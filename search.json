[{"path":[]},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"our-pledge","dir":"","previous_headings":"","what":"Our Pledge","title":"Contributor Covenant Code of Conduct","text":"members, contributors, leaders pledge make participation community harassment-free experience everyone, regardless age, body size, visible invisible disability, ethnicity, sex characteristics, gender identity expression, level experience, education, socio-economic status, nationality, personal appearance, race, religion, sexual identity orientation. pledge act interact ways contribute open, welcoming, diverse, inclusive, healthy community.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"our-standards","dir":"","previous_headings":"","what":"Our Standards","title":"Contributor Covenant Code of Conduct","text":"Examples behavior contributes positive environment community include: Demonstrating empathy kindness toward people respectful differing opinions, viewpoints, experiences Giving gracefully accepting constructive feedback Accepting responsibility apologizing affected mistakes, learning experience Focusing best just us individuals, overall community Examples unacceptable behavior include: use sexualized language imagery, sexual attention advances kind Trolling, insulting derogatory comments, personal political attacks Public private harassment Publishing others’ private information, physical email address, without explicit permission conduct reasonably considered inappropriate professional setting","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement-responsibilities","dir":"","previous_headings":"","what":"Enforcement Responsibilities","title":"Contributor Covenant Code of Conduct","text":"Community leaders responsible clarifying enforcing standards acceptable behavior take appropriate fair corrective action response behavior deem inappropriate, threatening, offensive, harmful. Community leaders right responsibility remove, edit, reject comments, commits, code, wiki edits, issues, contributions aligned Code Conduct, communicate reasons moderation decisions appropriate.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"scope","dir":"","previous_headings":"","what":"Scope","title":"Contributor Covenant Code of Conduct","text":"Code Conduct applies within community spaces, also applies individual officially representing community public spaces. Examples representing community include using official e-mail address, posting via official social media account, acting appointed representative online offline event.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement","dir":"","previous_headings":"","what":"Enforcement","title":"Contributor Covenant Code of Conduct","text":"Instances abusive, harassing, otherwise unacceptable behavior may reported project lead. complaints reviewed investigated promptly fairly. community leaders obligated respect privacy security reporter incident.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"enforcement-guidelines","dir":"","previous_headings":"","what":"Enforcement Guidelines","title":"Contributor Covenant Code of Conduct","text":"Community leaders follow Community Impact Guidelines determining consequences action deem violation Code Conduct:","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"id_1-correction","dir":"","previous_headings":"Enforcement Guidelines","what":"1. Correction","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Use inappropriate language behavior deemed unprofessional unwelcome community. Consequence: private, written warning community leaders, providing clarity around nature violation explanation behavior inappropriate. public apology may requested.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"id_2-warning","dir":"","previous_headings":"Enforcement Guidelines","what":"2. Warning","title":"Contributor Covenant Code of Conduct","text":"Community Impact: violation single incident series actions. Consequence: warning consequences continued behavior. interaction people involved, including unsolicited interaction enforcing Code Conduct, specified period time. includes avoiding interactions community spaces well external channels like social media. Violating terms may lead temporary permanent ban.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"id_3-temporary-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"3. Temporary Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: serious violation community standards, including sustained inappropriate behavior. Consequence: temporary ban sort interaction public communication community specified period time. public private interaction people involved, including unsolicited interaction enforcing Code Conduct, allowed period. Violating terms may lead permanent ban.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"id_4-permanent-ban","dir":"","previous_headings":"Enforcement Guidelines","what":"4. Permanent Ban","title":"Contributor Covenant Code of Conduct","text":"Community Impact: Demonstrating pattern violation community standards, including sustained inappropriate behavior, harassment individual, aggression toward disparagement classes individuals. Consequence: permanent ban sort public interaction within community.","code":""},{"path":"https://parallelly.futureverse.org/CONDUCT.html","id":"attribution","dir":"","previous_headings":"","what":"Attribution","title":"Contributor Covenant Code of Conduct","text":"Code Conduct adapted Contributor Covenant, version 2.0, available https://www.contributor-covenant.org/version/2/0/code_of_conduct.html. Community Impact Guidelines inspired Mozilla’s code conduct enforcement ladder. answers common questions code conduct, see FAQ https://www.contributor-covenant.org/faq. Translations available https://www.contributor-covenant.org/translations.","code":""},{"path":"https://parallelly.futureverse.org/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributing to the ‘parallelly’ package","title":"Contributing to the ‘parallelly’ package","text":"Git repository uses Git Flow branching model (git flow extension useful ). develop branch contains latest contributions code appear next release, master branch contains code latest release, exactly currently CRAN. Contributing package easy. Just send pull request. send PR, make sure develop destination branch parallelly repository. PR pass R CMD check ---cran, also checked GitHub Actions PR submitted. abide Code Conduct Contributor Covenant.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-01-intro.html","id":"compatibility-with-the-parallel-package","dir":"Articles","previous_headings":"","what":"Compatibility with the parallel package","title":"An Introduction to 'parallelly'","text":"cluster created parallelly package fully compatible clusters created parallel package can used parallel’s functions cluster processing, e.g. parallel::clusterEvalQ() parallel::parLapply(). parallelly::makeClusterPSOCK() function can used stand-replacement parallel::makePSOCKcluster(), equivalently, parallel::makeCluster(..., type = \"PSOCK\"). parallelly functions apply also clusters created parallel package. example, makes cluster created parallel shut automatically R’s garbage collector removes cluster object. lowers risk leaving stray R worker processes running background mistake. Another way achieve single call use:","code":"cl <- parallel::makeCluster(2) cl <- parallelly::autoStopCluster(cl) cl <- parallelly::makeClusterPSOCK(2, autoStop = TRUE)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-01-intro.html","id":"availablecores-vs-paralleldetectcores","dir":"Articles","previous_headings":"Compatibility with the parallel package","what":"availableCores() vs parallel::detectCores()","title":"An Introduction to 'parallelly'","text":"availableCores() function designed better, safer alternative detectCores() parallel package. designed worry-free solution developers end-users query number available cores - solution plays nice multi-tenant systems, Linux containers, high-performance compute (HPC) cluster, CRAN Bioconductor check servers, elsewhere. know parallel::detectCores() might return NA systems, parallel::detectCores() - 1 might return 0 systems, e.g. old hardware virtual machines? , use max(1, parallel::detectCores() - 1, na.rm = TRUE) get correct. contrast, parallelly::availableCores() guaranteed return positive integer, can use parallelly::availableCores(omit = 1) return one core always least one. Just like software tools “hijacks” cores default, R scripts, packages defaults detectCores() number parallel workers cause lots suffering fellow end-users system administrators. instance, shared server 48 cores come halt already users run parallel processing using detectCores() number parallel workers. problem gets worse machines many cores can host even concurrent users. R users used availableCores() instead, system administrator can limit number cores user get , say, two (2), setting environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK=2. contrast, possible override parallel::detectCores() returns, cf. PR#17641 - WISH: Make parallel::detectCores() agile new env var R_DEFAULT_CORES. Similarly, availableCores() also agile CPU limitations set Unix control groups (cgroups), often used Linux containers (e.g. Docker, Apptainer / Singularity, Podman) Kubernetes (K8s) environments. example, docker run --cpuset-cpus=0-2,8 ... sets CPU affinity processes can run CPUs 0, 1, 2, 8 host system. case availableCores() detects returns four (4). Another example docker run --cpu=3.4 ..., throttles CPU quota average 3.4 CPUs host system. case availableCores() detects returns three (3), rounds nearest integer. contrast, parallel::detectCores() completely ignores cgroups settings returns number CPUs host system, results CPU overuse degredated performance. Continous Integration (CI) services (e.g. GitHub Actions, Travis CI, Appveyor CI) cloud services (e.g. RStudio Cloud) use types cgroups settings hood, means availableCores() respects CPU allocations. running HPC cluster job scheduler, script uses availableCores() run number parallel workers job scheduler assigned job. example, submit Slurm job sbatch --cpus-per-task=16 ..., availableCores() returns 16, respects SLURM_* environment variables set scheduler. Son Grid Engine (SGE), scheduler sets NSLOTS submitting using qsub -pe smp 8 ... availableCores() returns eight (8). See help(\"availableCores\", package = \"parallelly\") currently supported job schedulers, includes ‘Fujitsu Technical Computing Suite’, ‘Load Sharing Facility’ (LSF), Simple Linux Utility Resource Management (Slurm), Sun Grid Engine/Oracle Grid Engine/Son Grid Engine (SGE), Univa Grid Engine (UGE), TORQUE/PBS. course, availableCores() respects also R options environment variables commonly used specify number parallel workers, e.g. R option mc.cores Bioconductor environment variable BIOCPARALLEL_WORKER_NUMBER. also detect running R CMD check limit number workers two (2), maximum number parallel workers allowed CRAN Policies. way , package developer, know package always play rules CRAN Bioconductor. nothing set limits number cores, availableCores() falls back parallel::detectCores() returns NA_integer_ one (1) returned. table summarize benefits:","code":""},{"path":"https://parallelly.futureverse.org/articles/parallelly-01-intro.html","id":"backward-compatibility-with-the-future-package","dir":"Articles","previous_headings":"","what":"Backward compatibility with the future package","title":"An Introduction to 'parallelly'","text":"functions package originate future package used validated several years. moved functions separate package 2020, also useful outside future framework. backward-compatibility reasons future framework, R options environment variables prefixed parallelly.* R_PARALLELLY_* can time also set future.* R_FUTURE_* prefixes.","code":""},{"path":"https://parallelly.futureverse.org/articles/parallelly-01-intro.html","id":"roadmap","dir":"Articles","previous_headings":"","what":"Roadmap","title":"An Introduction to 'parallelly'","text":"Submit parallelly CRAN, minimal changes compared corresponding functions future package (CRAN 2020-10-20) Update future package import re-export functions parallelly maximize backward compatibility future framework (future 1.20.1 CRAN 2020-11-03) Switch use 10-15% faster useXDR=FALSE Implement fast parallel setup parallel PSOCK workers parallel (>= 4.0.0) validated negative impact future framework, allow changes parallelly package, e.g. renaming R options environment variable parallelly.* R_PARALLELLY_* falling back future.* R_FUTURE_* Add vignettes set cluster running local remote machines, including Linux containers popular cloud services, vignettes common problems troubleshoot Migrate, currently internal, UUID functions export , e.g. uuid(), connectionUuid(), sessionUuid() (https://github.com/HenrikBengtsson/Wishlist--R/issues/96). R built-md5 checksum function operates object, functions require us adding dependency digest package. Initially, backward compatibility future package top priority.","code":""},{"path":"https://parallelly.futureverse.org/articles/parallelly-10-local-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers on the Local Machine","text":"vignettes illustrates launch parallel workers current, local machine. works operating systems R supported, e.g. Linux, macOS, MS Windows.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-10-local-workers.html","id":"example-launching-two-parallel-workers","dir":"Articles","previous_headings":"Examples","what":"Example: Launching two parallel workers","title":"Parallel Workers on the Local Machine","text":"illustrates launch cluster two parallel workers current machine, run basic calculations paralllel, shut cluster. Comment: parallel package, parallel worker referred parallel node, short node, use term parallelly package. alternative specifying number parallel workers specify character vector number \"localhost\" entries, e.g.","code":"library(parallelly) library(parallel)  cl <- makeClusterPSOCK(2) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host 'localhost' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu)  y <- parLapply(cl, X = 1:100, fun = sqrt) y <- unlist(y) z <- sum(y) print(z) #> [1] 671.4629  parallel::stopCluster(cl) cl <- makeClusterPSOCK(c(\"localhost\", \"localhost\"))"},{"path":"https://parallelly.futureverse.org/articles/parallelly-10-local-workers.html","id":"example-launching-as-many-parallel-workers-as-allotted","dir":"Articles","previous_headings":"Examples","what":"Example: Launching as many parallel workers as allotted","title":"Parallel Workers on the Local Machine","text":"availableCores() function return number workers system allows. respects many common settings controls number CPU cores current R process alloted, e.g. R options, environment variables, CGroups settings. details, see help(\"availableCores\"). example,","code":"library(parallelly) cl <- makeClusterPSOCK(availableCores()) print(cl) #> Socket cluster with 8 nodes where 8 nodes are on host 'localhost' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers on Other Machines","text":"Sometimes sufficient parallize single computer - provide compute power looking . hit limit, natural next level look computers near us, e.g. desktops office computers access remotely. vignette, cover run parallel R workers machines. Sometimes distinguish local machines remote machines, local machines machines considered local area network (LAN) might share common file system. Remote machines machines different network share common file system main R computer. cases distinction local remote machines matter, cases can take advantages workers local. Regardless running parallel workers local remote machines, need way connect machines launch R .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"verifying-ssh-access","dir":"Articles","previous_headings":"Introduction > SSH and R configuration (once)","what":"Verifying SSH access","title":"Parallel Workers on Other Machines","text":"common approach connect another machine via Secure Shell (SSH). Linux, macOS, MS Windows built-SSH client called ssh. Consider another Linux machine called n1.remote.org, can accessed via SSH, account alice machine. case instructions, matter whether n1.remote.org local network (LAN) remote machine internet. Also, make clear username n1.remote.org local machine, use ally username local machine. access alice user account n1.remote.org local computer, open terminal local computer SSH machine : commands call follows prompt. prompt local machine {ally@local}$, tells us username ally name local machine local. prompt n1.remote.org machine {alice@n1}$, tells us username machine alice machine called n1 system. return local machine, exit SSH shell typing exit; get far, confirmed SSH access machine.","code":"{ally@local}$ ssh alice@n1.remote.org alice@n1.remote.org's password: ************* {alice@n1}$ {alice@n1}$ exit {ally@local}$"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"configure-password-less-ssh-access","dir":"Articles","previous_headings":"Introduction > SSH and R configuration (once)","what":"Configure password-less SSH access","title":"Parallel Workers on Other Machines","text":"Launching parallel R workers typically done automatically background, means cumbersome, even impossible, enter SSH password machine wish connect . solution configure SSH connect public-private keys, pre-establish SSH authentication main machine machine connect . common practice working SSH, numerous online tutorials explaining configure private-public SSH key pairs. Please consult one details, gist use () ssh-keygen generate public-private SSH keys local machine, (ii) ssh-copy-id deploy public key machine want connect . Step 1: Generate public-private SSH keys locally Step 2: Copy public SSH key machine point, able SSH machine without enter password; Type exit return local machine. Note, later want connect machines, e.g. n2.remote.org hpc.-university.edu, may re-use generated keys systems . words, use ssh-keygen generate new keys machines.","code":"{ally@local}$ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/ally/.ssh/id_rsa):  Created directory '/home/ally/.ssh'. Enter passphrase (empty for no passphrase):  Enter same passphrase again:  Your identification has been saved in /home/ally/.ssh/id_rsa Your public key has been saved in /home/ally/.ssh/id_rsa.pub The key fingerprint is: SHA256:Sx48uXZTUL12SKKUzWB77e/Pm3TifqrDIbOnJ0pEWHY ally@local The key's randomart image is: +---[RSA 3072]----+ |        o E=..   | |       + ooo+.o  | |      . ..o..o.o | |       o ..o .+ .| |        S   .... | |       + =o..  . | |        * o= ...o| |       o .o.=..++| |        ...=.++=*| +----[SHA256]-----+ {ally@local}$ ssh-copy-id alice@n1.remote.org /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/home/ally/.ssh/id_rsa.pub\" /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys alice@n1.remote.org:s password: *************  Number of key(s) added: 1  Now try logging into the machine, with:   \"ssh 'alice@n1.remote.org'\" and check to make sure that only the key(s) you wanted were added. {ally@local}$ ssh alice@n1.remote.org {alice@n1}$"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"verifying-r-exists-on-the-other-machine","dir":"Articles","previous_headings":"Introduction > SSH and R configuration (once)","what":"Verifying R exists on the other machine","title":"Parallel Workers on Other Machines","text":"order run parallel R workers another machine, () needs installed machine, (ii) ideally readily available calling Rscript. Parallel R workers launched via Rscript, instead commonly known R command - come R installation, .e. one , . verify R installed machine, SSH machine call Rscript --version; get: R either installed machine, found. installed, found, make sure environment variable PATH configured properly machine.","code":"{ally@local}$ ssh alice@n1.remote.org {alice@n1}$ Rscript --version Rscript (R) version 4.4.2 (2024-10-31) {alice@n1}$ Rscript --version Rscript: command not found"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"final-checks","dir":"Articles","previous_headings":"Introduction > SSH and R configuration (once)","what":"Final checks","title":"Parallel Workers on Other Machines","text":"password-less SSH access, R available, machine, able SSH machine query R version single call: needed launch one parallel R workers machine n1.remote.org running user alice. can test within R parallelly package using: want run parallel workers machines, repeat machine. , able launch parallel R workers machines little efforts.","code":"{ally@local}$ ssh alice@n1.remote.org Rscript --version Rscript (R) version 4.4.2 (2024-10-31) {ally@local}$ {ally@local}$ R --quiet library(parallely) cl <- makeClusterPSOCK(\"n1.remote.org\", user = \"alice\") print(cl) #> Socket cluster with 1 nodes where 1 node is on host 'n1.remote.org' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu) parallel::stopCluster(cl)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"machine-specific-ssh-customization-recommended","dir":"Articles","previous_headings":"Introduction > SSH and R configuration (once)","what":"Machine-specific SSH customization (recommended)","title":"Parallel Workers on Other Machines","text":"machines use default port 22 answer SSH connection requests. machine uses another port, say, port 2201, canspecify via option -p port, connect , e.g. R, can specify argument port=port : Now, can tedious remember custom SSH ports usernames setting remote workers R. also adds noise distraction details R script, mention fact R script specific username hardcoded code makes script less reproducible users - need change code match username. One way avoid give specific SSH options calling ssh terminal, makeClusterPSOCK() R, configure settings SSH. can done via file called ~/.ssh/config local machine. file exist default, create , missing. plain text file, use plain text editor create edit . configure SSH use port 2201 username alice whenever connecting n1.remote.org, ~/.ssh/config file contain following entry: , can connect n1.remote.org just using: SSH connect machine specified also -p 2201 -l alice. settings also picked connect via R, meaning following also work: achieve machines, add another entry , e.g. hosts system share setting, one can use globbing configure way. instance, can shorted : able connect remote machines just specifying hostnames convenient simplifies also R code. , recommend setting also ~/.ssh/config.","code":"{ally@local}$ ssh -p 2201 alice@n1.remote.org cl <- makeClusterPSOCK(\"n1.remote.org\", port = 2201, user = \"alice\") Host n1.remote.org   User alice   Port 2201 {ally@local}$ ssh n1.remote.org {alice@n1}$ cl <- makeClusterPSOCK(\"n1.remote.org\") Host n1.remote.org   User alice   Port 2201  Host n2.remote.org   User alice   Port 2201  Host hpc.my-university.edu   User alice.bobson Host n?.remote.org   User alice   Port 2201  Host hpc.my-university.edu   User alice.bobson"},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-two-parallel-workers-on-a-single-remote-machine","dir":"Articles","previous_headings":"Examples","what":"Example: Two parallel workers on a single remote machine","title":"Parallel Workers on Other Machines","text":"first example sets two parallel workers remote machine n1.remote.org. work, need SSH access machine, must R installed, explained section. Contrary local parallel workers, number parallel workers remote machines specified repeating machine name equal number times; Comment: parallel package, parallel worker referred parallel node, short node, use term parallelly package. Note, contrary parallel workers running local machine, parallel workers remote machines launched sequentially, one . , setup time remote parallel cluster increase linearly number remote parallel workers. Technical details: add verbose = TRUE makeClusterPSOCK(), learn parallel workers launched background R using something like: tells us one active SSH connection per parallel worker. also reveals connections uses called reverse tunnel, used establish unique communication channel main R process corresponding parallel worker. also use reverse tunneling avoids configure dynamic DNS (DDNS) port-forwarding local firewalls, cumbersome requires administrative rights. using parallelly, need administrative rights - non-privileged user can launch remote parallel R workers.","code":"library(parallelly) workers <- c(\"n1.remote.org\", \"n1.remote.org\") cl <- makeClusterPSOCK(workers, user = \"alice\") print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host 'n1.remote.org' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu). '/usr/bin/ssh' -R 11058:localhost:11058 -l alice n1.remote.org Rscript ... '/usr/bin/ssh' -R 11059:localhost:11059 -l alice n1.remote.org Rscript ..."},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-two-parallel-workers-on-two-remote-machines","dir":"Articles","previous_headings":"Examples","what":"Example: Two parallel workers on two remote machines","title":"Parallel Workers on Other Machines","text":"example sets parallel worker two remote machines n1.remote.org n2.remote.org. works similar previous example, now two SSH connections go two different machines rather . Technical details: add verbose = TRUE also case, see: Recall, configured SSH pick username alice ~/.ssh/config local machine, shown previous section, skipped user argument, just used: Note instructions setting parallel cluster two machines identical another user configured personal ~/.ssh/config file.","code":"library(parallelly) workers <- c(\"n1.remote.org\", \"n2.remote.org\") cl <- makeClusterPSOCK(workers, user = \"alice\") print(cl) #> Socket cluster with 2 nodes where 1 node is on host 'n1.remote.org' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu),  #> 1 node is on host 'n2.remote.org' (R version 4.4.2 (2024-10-31), #> platform x86_64-pc-linux-gnu) '/usr/bin/ssh' -R 11464:localhost:11464 -l alice n1.remote.org Rscript ... '/usr/bin/ssh' -R 11465:localhost:11464 -l alice n2.remote.org Rscript ... workers <- c(\"n1.remote.org\", \"n2.remote.org\") cl <- makeClusterPSOCK(workers)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-three-parallel-workers-on-two-remote-machines","dir":"Articles","previous_headings":"Examples","what":"Example: Three parallel workers on two remote machines","title":"Parallel Workers on Other Machines","text":"now understand control number parallel workers specific machine replicate machine name, also know launch different number parallel workers different machines. now , also assume remote username longer specified, already configured via ~/.ssh/config file. , can sets two parallel workers n1.remote.org one n2.remote.org, : , user argument specified, configured ~/.ssh/config. generalize many workers, can use rep() function. example, sets three workers n1.remote.org four n2.remote.org, totaling seven parallel workers.","code":"library(parallelly) workers <- c(\"n1.remote.org\", \"n1.remote.org\", \"n2.remote.org\") cl <- makeClusterPSOCK(workers) print(cl) #> Socket cluster with 3 nodes where 2 nodes are on host 'n1.remote.org' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu),  #> 1 node is on host 'n2.remote.org' (R version 4.4.2 (2024-10-31), #> platform x86_64-pc-linux-gnu) workers <- c(rep(\"n1.remote.org\", 3), rep(\"n2.remote.org\", 4))"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-a-mix-of-local-and-remote-workers","dir":"Articles","previous_headings":"Examples","what":"Example: A mix of local and remote workers","title":"Parallel Workers on Other Machines","text":"alternative makeClusterPSOCK(n), can use makeClusterPSOCK(workers) set parallelly workers running local machine. convention, name localhost alias local machine. means, can use: launch four local parallel workers. Note specify user = \"ally\". default username always local username. Next, assume want add another four parallel workers running n1.remote.org. already know can set : point, two independent clusters parallel workers: cl_local cl_remote. can combine single cluster using: emphasize usefulness customizing SSH connections via ~/.ssh/config, remote username already already configured , able set full cluster one single call, :","code":"library(parallelly) workers <- rep(\"localhost\", 4) cl_local <- makeClusterPSOCK(workers) print(cl_local) #> Socket cluster with 4 nodes where 4 nodes are on host 'localhost' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu) library(parallelly) workers <- rep(\"n1.remote.org\", 4) cl_remote <- makeClusterPSOCK(workers, user = \"alice\") print(cl_remote) #> Socket cluster with 4 nodes where 4 nodes are on host 'n1.remote.org' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu). cl <- c(cl_local, cl_remote) print(cl) #> Socket cluster with 8 nodes where 4 nodes are on host 'localhost' #> (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu), 4 #> nodes are on host 'n1.remote.org' (R version 4.4.2 (2024-10-31), #> platform x86_64-pc-linux-gnu) library(parallelly) workers <- c(rep(\"localhost\", 4), rep(\"n1.remote.org\", 4) cl <- makeClusterPSOCK(workers)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-parallel-workers-on-a-remote-machine-accessed-via-dedicated-login-machine","dir":"Articles","previous_headings":"Examples","what":"Example: Parallel workers on a remote machine accessed via dedicated login machine","title":"Parallel Workers on Other Machines","text":"Sometimes remote machine, want run R, accessible via intermediate login machine, SSH terms may also referred “jumphost”. example, assume machine secret1.remote.org can accessed first logging login.remote.org : achive single SSH call, can specify “jumphost” -J hostname option SSH, : can use rshopts argument makeClusterPSOCK() achieve setting parallel workers. launch three parallel workers secret1.remote.org, use: convenient solution configure jumphost ~/.ssh/config, : cause SSH connection machine remote.org network use username alice. also cause SSH connection machines secret1.remote.org, secret2.remote.org, , use jumphost login.remote.org. can verify work : : work, following work within R:","code":"{ally@local}$ ssh alice@login.remote.org {alice@login}$ ssh alice@secret1.remote.org {alice@secret1}$ {ally@local}$ ssh -J alice@login.remote.org alice@secret1.remote.org {alice@secret1}$ workers <- rep(\"secret1.remote.org\", 3) cl <- makeClusterPSOCK(   workers,   rshopts = c(\"-J\", \"login.remote.org\"),   user = \"alice\" ) Host *.remote.org   User alice  Host secret?.remote.org   ProxyJump login.remote.org {ally@local}$ ssh login.remote.org {alice@login}$ {ally@local}$ ssh secret1.remote.org {alice@secret1}$ library(parallelly) workers <- rep(\"secret1.remote.org\", 3) cl <- makeClusterPSOCK(workers)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"special-needs-and-tweaks","dir":"Articles","previous_headings":"","what":"Special needs and tweaks","title":"Parallel Workers on Other Machines","text":"sections cover common use cases setting parallel cluster local Linux, macOS, MS Windows machine. However, cases work, prefer use another solution. section aims cover alternatives.","code":""},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-remote-workers-ignoring-any-remote--rprofile-settings","dir":"Articles","previous_headings":"Special needs and tweaks","what":"Example: Remote workers ignoring any remote .Rprofile settings","title":"Parallel Workers on Other Machines","text":"launch parallel workers skipping ~/.Rprofile settings remote machines, can pass option ---init-file Rscript via argument rscript_args. example, launch two parallel workers n1.remote.org ignoring .Rprofile files.","code":"workers <- rep(\"n1.remote.org\", 2) cl <- makeClusterPSOCK(workers, rscript_args = \"--no-init-file\")"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-use-putty-on-ms-windows-to-connect-to-remote-worker","dir":"Articles","previous_headings":"Special needs and tweaks","what":"Example: Use PuTTY on MS Windows to connect to remote worker","title":"Parallel Workers on Other Machines","text":"run MS Windows machine prefer use PuTTY manage SSH connections, reasons use built-ssh client, can tell makeClusterPSOCK() use PuTTY PuTTY settings via various arguments. example launches two parallel workers n1.remote.org running user alice connecting via SSH port 2201 using PuTTY public-private SSH keys file C:/Users/ally/.ssh/putty.ppk:","code":"workers <- \"n1.remote.org\" cl <- makeClusterPSOCK(   workers,    user = \"alice\",   rshcmd = \"<putty-plink>\",   rshopts = c(\"-P\", 2201, \"-i\", \"C:/Users/ally/.ssh/putty.ppk\") )"},{"path":"https://parallelly.futureverse.org/articles/parallelly-12-remote-workers.html","id":"example-two-remote-workers-running-on-ms-windows","dir":"Articles","previous_headings":"Special needs and tweaks","what":"Example: Two remote workers running on MS Windows","title":"Parallel Workers on Other Machines","text":"Thus far considered remote machines run Unix-like operating system, e.g. Linux macOS. remote machines run MS Windows, can use similar techniques launch parallel workers well. work, remote MS Windows machines must accept incoming SSH connections, something Windows machines configured default. know set , system permissions , please reach system administrator machines. Assuming SSH access two MS Windows machines, mswin1.remote.org mswin2.remote.org, everything works , except need specify also argument rscript_sh = \"cmd\"; argument specifies parallel R workers launched remote machines via MS Windows’ cmd.exe shell.","code":"workers <- c(\"mswin1.remote.org\", \"mswin2.remote.org\") cl <- makeClusterPSOCK(workers, rscript_sh = \"cmd\")"},{"path":"https://parallelly.futureverse.org/articles/parallelly-15-cloud-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers in the Cloud","text":"vignettes illustrates launch parallel workers cloud services Amazon AWS (https://aws.amazon.com/) Google Compute Engine (https://cloud.google.com/products/compute).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-15-cloud-workers.html","id":"example-remote-worker-running-on-gce","dir":"Articles","previous_headings":"Examples","what":"Example: Remote worker running on GCE","title":"Parallel Workers in the Cloud","text":"example launches parallel worker Google Compute Engine (GCE) running container based VM (#cloud-config specification).","code":"library(parallelly)  public_ip <- \"1.2.3.4\" user <- \"johnny\" ssh_private_key_file <- \"~/.ssh/google_compute_engine\" cl <- makeClusterPSOCK(   ## Public IP number of GCE instance   public_ip,   ## User name (== SSH key label (sic!))   user = user,   ## Use private SSH key registered with GCE   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Launch Rscript inside Docker container   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ) )"},{"path":"https://parallelly.futureverse.org/articles/parallelly-15-cloud-workers.html","id":"example-remote-worker-running-on-aws","dir":"Articles","previous_headings":"Examples","what":"Example: Remote worker running on AWS","title":"Parallel Workers in the Cloud","text":"example, bit dated, launches parallel worker Amazon AWS EC2 running one Amazon Machine Images (AMI) provided Posit (https://www.louisaslett.com/RStudio_AMI/).","code":"library(parallelly)  public_ip <- \"1.2.3.4\" ssh_private_key_file <- \"~/.ssh/my-private-aws-key.pem\"  cl <- makeClusterPSOCK(   ## Public IP number of EC2 instance   public_ip,   ## User name (always 'ubuntu')   user = \"ubuntu\",   ## Use private SSH key registered with AWS   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Set up .libPaths() for the 'ubuntu' user   ## and then install the future package   rscript_startup = quote(local({     p <- Sys.getenv(\"R_LIBS_USER\")     dir.create(p, recursive = TRUE, showWarnings = FALSE)     .libPaths(p)     install.packages(\"future\")   })) )"},{"path":"https://parallelly.futureverse.org/articles/parallelly-17-hpc-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers on High-Performance Compute Environments","text":"vignettes illustrates launch parallel workers via job schedulers running high-performance compute (HPC) environments.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-17-hpc-workers.html","id":"example-launch-parallel-workers-via-the-grid-engine-job-scheduler","dir":"Articles","previous_headings":"Examples","what":"Example: Launch parallel workers via the Grid Engine job scheduler","title":"Parallel Workers on High-Performance Compute Environments","text":"‘Grid Engine’ high-performance compute (HPC) job scheduler one can request compute resources multiple nodes, running multiple cores. Examples Grid Engine schedulers Oracle Grid Engine (formerly Sun Grid Engine), Univa Grid Engine, Son Grid Engine - commonly referred SGE schedulers. SGE cluster may configuration way requesting parallel slots. Consider following two files: script.sh script.R. script.sh: script.R: script.sh file job script submit scheduler runs R script script.R launched. submit script.sh : default request eight slots - one machines, R parallelly set parallel cluster . many, machines, parallel workers run depends job scheduler finds requested slots . output one run, scheduler happened allot slots across three machines:","code":"#! /usr/bin/env bash #$ -cwd               ## Run in current working directory #$ -j y               ## Merge stdout and stderr #$ -l mem_free=100M   ## 100 MiB RAM per slot #$ -l h_rt=00:10:00   ## 10 minutes runtime  #$ -pe mpi 8          ## 8 compute slots  echo \"Information on R:\" Rscript --version  echo \"Running R script:\" Rscript script.R library(parallelly) library(parallel)  cl <- makeClusterPSOCK(   availableWorkers(),   rshcmd = \"qrsh\", rshopts = c(\"-inherit\", \"-nostdin\", \"-V\") ) print(cl)  # Perform calculations in parallel X <- 1:100 y <- parLapply(cl = cl, X, fun = sqrt) y <- unlist(y) z <- sum(y) print(z)  stopCluster(cl) $ qsub script.sh Information on R: Rscript (R) version 4.4.2 (2024-10-31) Running R script: Socket cluster with 8 nodes where 4 nodes are on host ‘localhost’ (R version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu), 3 nodes are on host ‘qb3-id130’ (R version 4.4.2 (2024-10-31),  platform x86_64-pc-linux-gnu), 1 node is on host ‘qb3-as16’ (R  version 4.4.2 (2024-10-31), platform x86_64-pc-linux-gnu) [1] 671.4629"},{"path":"https://parallelly.futureverse.org/articles/parallelly-17-hpc-workers.html","id":"example-launch-parallel-workers-via-thefujitsu-technical-computing-suite-job-scheduler","dir":"Articles","previous_headings":"Examples","what":"Example: Launch parallel workers via the’Fujitsu Technical Computing Suite job scheduler","title":"Parallel Workers on High-Performance Compute Environments","text":"‘Fujitsu Technical Computing Suite’ high-performance compute (HPC) job scheduler one can request compute resources multiple nodes, running multiple cores. Consider following two files: script.sh script.R. script.sh: script.R: script.sh file job script submit scheduler runs R script script.R launched. Wee can submit script.sh : request 18 CPU cores three compute nodes, total requests 3*18=54 compute slots.","code":"#! /usr/bin/env bash  echo \"Information on R:\" Rscript --version  echo \"Running R script:\" Rscript script.R library(parallelly) library(parallel)  cl <- makeClusterPSOCK(   availableWorkers(),   rshcmd = \"pjrsh\" ) print(cl)  # Perform calculations in parallel X <- 1:100 y <- parLapply(cl = cl, X, fun = sqrt) y <- unlist(y) z <- sum(y) print(z)  stopCluster(cl) $ pjsub -L vnode=3 -L vnode-core=18 script.sh"},{"path":"https://parallelly.futureverse.org/articles/parallelly-20-limit-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers with CPU and Memory Limited","text":"vignette gives examples restrict CPU memory usage parallel workers. can useful optimizing performance parallel workers, also lower risk overuse CPU memory machines running .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-20-limit-workers.html","id":"example-linux-parallel-workers-with-a-lower-process-priority-nice","dir":"Articles","previous_headings":"Examples","what":"Example: Linux parallel workers with a lower process priority (“nice”)","title":"Parallel Workers with CPU and Memory Limited","text":"Unix, can run process lower CPU priority using nice command. can used want lower risk negatively affecting users processes run machine R workers overusing CPUs mistake. achieve , can prepend nice Rscript call via rscript argument using. works local remote Linux machines, e.g. special * value expands proper Rscript machine parallel workers launched.","code":"library(parallelly) cl <- makeClusterPSOCK(2, rscript = c(\"nice\", \"*\")) library(parallelly) workers <- rep(\"n1.remote.org\", 2) cl <- makeClusterPSOCK(2, rscript = c(\"nice\", \"*\"))"},{"path":"https://parallelly.futureverse.org/articles/parallelly-20-limit-workers.html","id":"example-linux-parallel-workers-cpu-and-memory-limited-by-cgroups","dir":"Articles","previous_headings":"Examples","what":"Example: Linux parallel workers CPU and memory limited by CGroups","title":"Parallel Workers with CPU and Memory Limited","text":"example launches two parallel workers limited 100% CPU quota 50 MiB memory using Linux CGroups management. 100% CPU quota limit constrain worker use one CPU worth processing preventing overusing machine, e.g. unintended nested parallelization. details, see man systemd.resource-control. Note, depending CGroups configuration, non-privileged user may may able set CPU quota. , -p CPUQuota=100% silently ignored. 50 MiB memory limit strict - worker use , operating system terminate worker instantly. illustrate happens, first start generating 1 million numeric values consuming 8 bytes, total consumes ~8 MB, calculate mean, memory consumption within 50-MiB memory limit parallel worker available; However, generate 10 times values, memory consumption grow least 80 MB, 50-MiB memory limit, get error: operating system terminated two background R processes, overused memory. main R process longer can communicate parallel workers. can see workers , calling: can use cloneNode() relaunch workers longer alive, e.g.","code":"library(parallelly) cl <- makeClusterPSOCK(   2L,   rscript = c(     \"systemd-run\", \"--user\", \"--scope\",     \"-p\", \"CPUQuota=100%\",     \"-p\", \"MemoryMax=50M\", \"-p\", \"MemorySwapMax=50M\",     \"*\"   ) ) library(parallel) mu <- clusterEvalQ(cl, { x <- rnorm(n = 1e6); mean(x) }) mu <- unlist(mu) print(mu) #> [1]  0.0008072657 -0.0019693992 mu <- clusterEvalQ(cl, { x <- rnorm(n = 10e6); mean(x) }) #> Error in unserialize(node$con) : error reading from connection isNodeAlive(cl) #> [1] FALSE FALSE is_down <- !isNodeAlive(cl) cl[is_down] <- cloneNode(cl[is_down]) isNodeAlive(cl) #> [1] TRUE TRUE"},{"path":"https://parallelly.futureverse.org/articles/parallelly-20-limit-workers.html","id":"example-ms-windows-parallel-workers-with-specific-cpu-affinities","dir":"Articles","previous_headings":"Examples","what":"Example: MS Windows parallel workers with specific CPU affinities","title":"Parallel Workers with CPU and Memory Limited","text":"example, works MS Windows machines. launches four local workers, two running CPU Group #0 two CPU Group #1. special * value expands proper Rscript machine parallel workers launched.","code":"library(parallelly) rscript <- I(c(   Sys.getenv(\"COMSPEC\"), \"/c\",    \"start\", \"/B\",   \"/NODE\", cpu_group=NA_integer_,    \"/AFFINITY\", \"0xFFFFFFFFFFFFFFFE\",    \"*\") )  rscript[\"cpu_group\"] <- 0 cl_0 <- makeClusterPSOCK(2, rscript = rscript)  rscript[\"cpu_group\"] <- 1 cl_1 <- makeClusterPSOCK(2, rscript = rscript)  cl <- c(cl_0, cl_1)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-21-container-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers Running in Linux Containers","text":"vignette shows set parallel workers running Linux containers, e.g. Docker (https://www.docker.com/), Apptainer (https://apptainer.org/), udocker (https://indigo-dc.github.io/udocker/).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-21-container-workers.html","id":"example-two-parallel-workers-running-in-docker","dir":"Articles","previous_headings":"Examples","what":"Example: Two parallel workers running in Docker","title":"Parallel Workers Running in Linux Containers","text":"example sets two parallel workers running Docker image ‘rocker/r-parallel’ (https://hub.docker.com/r/rocker/r-parallel).","code":"library(parallelly) cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Linux container via Docker   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ),   ## IMPORTANT: Because Docker runs inside a virtual machine (VM) on macOS   ## and MS Windows (not Linux), when the R worker tries to connect back to   ## the default 'localhost' it will fail, because the main R session is   ## not running in the VM, but outside on the host.  To reach the host on   ## macOS and MS Windows, make sure to use master = \"host.docker.internal\"   master = if (.Platform$OS.type == \"unix\") NULL else \"host.docker.internal\", ) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host 'localhost' #> (R version 4.3.3 (2024-02-29), platform x86_64-pc-linux-gnu)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-21-container-workers.html","id":"example-two-parallel-workers-running-in-apptainer","dir":"Articles","previous_headings":"Examples","what":"Example: Two parallel workers running in Apptainer","title":"Parallel Workers Running in Linux Containers","text":"example shows set two parallel workers running Docker image ‘rocker/r-parallel’ (https://hub.docker.com/r/rocker/r-parallel) via Apptainer (<https://apptainer.org/).","code":"library(parallelly) cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Linux container via Apptainer   rscript = c(     \"apptainer\", \"exec\", \"docker://rocker/r-parallel\",     \"Rscript\"   ) ) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host 'localhost' #> (R version 3.6.1 (2019-07-05), platform x86_64-pc-linux-gnu)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-21-container-workers.html","id":"example-two-parallel-workers-running-in-udocker","dir":"Articles","previous_headings":"Examples","what":"Example: Two parallel workers running in udocker","title":"Parallel Workers Running in Linux Containers","text":"example shows set two parallel workers running Docker image ‘rocker/r-parallel’ (https://hub.docker.com/r/rocker/r-parallel) via udocker (https://indigo-dc.github.io/udocker/).","code":"library(parallelly) cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Linux container via Docker   rscript = c(     \"udocker\", \"--quiet\", \"run\", \"rocker/r-parallel\",     \"Rscript\"   ) ) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host 'localhost' #> (R version 3.6.1 (2019-07-05), platform x86_64-pc-linux-gnu)"},{"path":"https://parallelly.futureverse.org/articles/parallelly-22-wine-workers.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Parallel Workers Running MS Windows via Wine","text":"vignette shows set parallel workers running MS Windows via Wine (https://www.winehq.org/) Linux macOS.","code":""},{"path":"https://parallelly.futureverse.org/articles/parallelly-22-wine-workers.html","id":"install-r-for-ms-windows-10","dir":"Articles","previous_headings":"Introduction","what":"Install R for MS Windows 10","title":"Parallel Workers Running MS Windows via Wine","text":"install R MS Windows Wine, first configure Wine use Windows 10; GUI, set ‘Windows version’ ‘Windows 10’. , install R Windows Wine, : Finally, verify R available Wine;","code":"$ winecfg $ wget https://cran.r-project.org/bin/windows/base/R-4.4.2-win.exe $ wine R-4.4.2-win.exe /SILENT $ wine \"C:/Program Files/R/R-4.4.2/bin/x64/Rscript.exe\" --version ... Rscript (R) version 4.4.2 (2024-10-31)"},{"path":[]},{"path":"https://parallelly.futureverse.org/articles/parallelly-22-wine-workers.html","id":"example-parallel-workers-running-ms-windows-via-wine","dir":"Articles","previous_headings":"Examples","what":"Example: Parallel workers running MS Windows via Wine","title":"Parallel Workers Running MS Windows via Wine","text":"example shows launch one worker running Wine Linux local machine.","code":"cl <- makeClusterPSOCK(   1L,   rscript = c(     ## Silence Wine warnings     \"WINEDEBUG=fixme-all\",     ## Don't pass LC_* and R_LIBS* environments from host to Wine     sprintf(\"%s=\", grep(\"^(LC_|R_LIBS)\", names(Sys.getenv()), value = TRUE)),     \"wine\",     \"C:/Program Files/R/R-4.4.2/bin/x64/Rscript.exe\"   ) ) print(cl) #> Socket cluster with 1 nodes where 1 node is on host 'localhost' #> (R version 4.4.2 (2024-10-31 ucrt), platform x86_64-w64-mingw32)"},{"path":"https://parallelly.futureverse.org/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Henrik Bengtsson. Author, maintainer, copyright holder. Mike Cheng. Contributor.","code":""},{"path":"https://parallelly.futureverse.org/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Bengtsson H (2025). parallelly: Enhancing 'parallel' Package. R package version 1.43.0-9005, https://parallelly.futureverse.org.","code":"@Manual{,   title = {parallelly: Enhancing the 'parallel' Package},   author = {Henrik Bengtsson},   year = {2025},   note = {R package version 1.43.0-9005},   url = {https://parallelly.futureverse.org}, }"},{"path":"https://parallelly.futureverse.org/index.html","id":"parallelly-enhancing-the-parallel-package-","dir":"","previous_headings":"","what":"Enhancing the parallel Package","title":"Enhancing the parallel Package","text":"parallelly package provides functions enhance parallel packages. example, availableCores() gives number CPU cores available R process given R options environment variables, including set job schedulers high-performance compute (HPC) clusters. R runs ‘cgroups’ Linux container, settings acknowledges . nothing else set, fall back parallel::detectCores(). Another example makeClusterPSOCK(), backward compatible parallel::makePSOCKcluster() better job setting remote cluster workers without know local public IP address configuring firewall port-forwarding local computer. functions features added package written backward compatible parallel package, may incorporated later. parallelly package comes open invitation R Core Team adopt parts code parallel package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/index.html","id":"compatibility-with-the-parallel-package","dir":"","previous_headings":"","what":"Compatibility with the parallel package","title":"Enhancing the parallel Package","text":"cluster created parallelly package fully compatible clusters created parallel package can used parallel’s functions cluster processing, e.g. parallel::clusterEvalQ() parallel::parLapply(). parallelly::makeClusterPSOCK() function can used stand-replacement parallel::makePSOCKcluster(), equivalently, parallel::makeCluster(..., type = \"PSOCK\"). parallelly functions apply also clusters created parallel package. example, makes cluster created parallel shut automatically R’s garbage collector removes cluster object. lowers risk leaving stray R worker processes running background mistake. Another way achieve single call use:","code":"cl <- parallel::makeCluster(2) cl <- parallelly::autoStopCluster(cl) cl <- parallelly::makeClusterPSOCK(2, autoStop = TRUE)"},{"path":"https://parallelly.futureverse.org/index.html","id":"availablecores-vs-paralleldetectcores","dir":"","previous_headings":"Compatibility with the parallel package","what":"availableCores() vs parallel::detectCores()","title":"Enhancing the parallel Package","text":"availableCores() function designed better, safer alternative detectCores() parallel package. designed worry-free solution developers end-users query number available cores - solution plays nice multi-tenant systems, Linux containers, high-performance compute (HPC) cluster, CRAN Bioconductor check servers, elsewhere. know parallel::detectCores() might return NA systems, parallel::detectCores() - 1 might return 0 systems, e.g. old hardware virtual machines? , use max(1, parallel::detectCores() - 1, na.rm = TRUE) get correct. contrast, parallelly::availableCores() guaranteed return positive integer, can use parallelly::availableCores(omit = 1) return one core always least one. Just like software tools “hijacks” cores default, R scripts, packages defaults detectCores() number parallel workers cause lots suffering fellow end-users system administrators. instance, shared server 48 cores come halt already users run parallel processing using detectCores() number parallel workers. problem gets worse machines many cores can host even concurrent users. R users used availableCores() instead, system administrator can limit number cores user get , say, two (2), setting environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK=2. contrast, possible override parallel::detectCores() returns, cf. PR#17641 - WISH: Make parallel::detectCores() agile new env var R_DEFAULT_CORES. Similarly, availableCores() also agile CPU limitations set Unix control groups (cgroups), often used Linux containers (e.g. Docker, Apptainer / Singularity, Podman) Kubernetes (K8s) environments. example, docker run --cpuset-cpus=0-2,8 ... sets CPU affinity processes can run CPUs 0, 1, 2, 8 host system. case availableCores() detects returns four (4). Another example docker run --cpu=3.4 ..., throttles CPU quota average 3.4 CPUs host system. case availableCores() detects returns three (3), rounds nearest integer. contrast, parallel::detectCores() completely ignores cgroups settings returns number CPUs host system, results CPU overuse degredated performance. Continous Integration (CI) services (e.g. GitHub Actions, Travis CI, Appveyor CI) cloud services (e.g. RStudio Cloud) use types cgroups settings hood, means availableCores() respects CPU allocations. running HPC cluster job scheduler, script uses availableCores() run number parallel workers job scheduler assigned job. example, submit Slurm job sbatch --cpus-per-task=16 ..., availableCores() returns 16, respects SLURM_* environment variables set scheduler. Son Grid Engine (SGE), scheduler sets NSLOTS submitting using qsub -pe smp 8 ... availableCores() returns eight (8). See help(\"availableCores\", package = \"parallelly\") currently supported job schedulers, includes ‘Fujitsu Technical Computing Suite’, ‘Load Sharing Facility’ (LSF), Simple Linux Utility Resource Management (Slurm), Sun Grid Engine/Oracle Grid Engine/Son Grid Engine (SGE), Univa Grid Engine (UGE), TORQUE/PBS. course, availableCores() respects also R options environment variables commonly used specify number parallel workers, e.g. R option mc.cores Bioconductor environment variable BIOCPARALLEL_WORKER_NUMBER. also detect running R CMD check limit number workers two (2), maximum number parallel workers allowed CRAN Policies. way , package developer, know package always play rules CRAN Bioconductor. nothing set limits number cores, availableCores() falls back parallel::detectCores() returns NA_integer_ one (1) returned. table summarize benefits:","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"backward-compatibility-with-the-future-package","dir":"","previous_headings":"","what":"Backward compatibility with the future package","title":"Enhancing the parallel Package","text":"functions package originate future package used validated several years. moved functions separate package 2020, also useful outside future framework. backward-compatibility reasons future framework, R options environment variables prefixed parallelly.* R_PARALLELLY_* can time also set future.* R_FUTURE_* prefixes.","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"roadmap","dir":"","previous_headings":"","what":"Roadmap","title":"Enhancing the parallel Package","text":"Submit parallelly CRAN, minimal changes compared corresponding functions future package (CRAN 2020-10-20) Update future package import re-export functions parallelly maximize backward compatibility future framework (future 1.20.1 CRAN 2020-11-03) Switch use 10-15% faster useXDR=FALSE Implement fast parallel setup parallel PSOCK workers parallel (>= 4.0.0) validated negative impact future framework, allow changes parallelly package, e.g. renaming R options environment variable parallelly.* R_PARALLELLY_* falling back future.* R_FUTURE_* Add vignettes set cluster running local remote machines, including Linux containers popular cloud services, vignettes common problems troubleshoot Migrate, currently internal, UUID functions export , e.g. uuid(), connectionUuid(), sessionUuid() (https://github.com/HenrikBengtsson/Wishlist--R/issues/96). R built-md5 checksum function operates object, functions require us adding dependency digest package. Initially, backward compatibility future package top priority.","code":""},{"path":"https://parallelly.futureverse.org/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Enhancing the parallel Package","text":"R package parallelly available CRAN can installed R :","code":"install.packages(\"parallelly\")"},{"path":"https://parallelly.futureverse.org/index.html","id":"pre-release-version","dir":"","previous_headings":"Installation","what":"Pre-release version","title":"Enhancing the parallel Package","text":"install pre-release version available Git branch develop GitHub, use: install package source. package also compiles native code, Windows users need Rtools installed macOS users need Xcode installed.","code":"remotes::install_github(\"futureverse/parallelly\", ref=\"develop\")"},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce an Object to a Cluster Object — as.cluster","title":"Coerce an Object to a Cluster Object — as.cluster","text":"Coerce Object Cluster Object","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce an Object to a Cluster Object — as.cluster","text":"","code":"as.cluster(x, ...)  # S3 method for class 'cluster' as.cluster(x, ...)  # S3 method for class 'list' as.cluster(x, ...)  # S3 method for class 'SOCKnode' as.cluster(x, ...)  # S3 method for class 'SOCK0node' as.cluster(x, ...)  # S3 method for class 'RichSOCKnode' as.cluster(x, ...)  # S3 method for class 'cluster' c(..., recursive = FALSE)"},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce an Object to a Cluster Object — as.cluster","text":"x object coerced. recursive used. ... Additional arguments passed underlying coercion method. c(...), clusters cluster nodes combined.","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce an Object to a Cluster Object — as.cluster","text":"object class cluster. c(...) combine multiple clusters / cluster nodes one cluster returned class cluster.  warning produced duplicated nodes resulting cluster.","code":""},{"path":"https://parallelly.futureverse.org/reference/as.cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coerce an Object to a Cluster Object — as.cluster","text":"","code":"cl1 <- makeClusterPSOCK(2, dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, start worker #1 on local machine ‘localhost’ with: #>  #>   '/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11288 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> ---------------------------------------------------------------------- #> Manually, start worker #2 on local machine ‘localhost’ with: #>  #>   '/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11288 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  cl2 <- makeClusterPSOCK(c(\"n1\", \"server.remote.org\"), dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, (i) login into external machine ‘n1’: #>  #>   '/usr/bin/ssh' -R 11925:localhost:11925 n1 #>  #> and (ii) start worker #1 from there: #>  #>   '/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11925 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> Alternatively, start worker #1 from the local machine by combining both steps in a single call: #>  #>   '/usr/bin/ssh' -R 11925:localhost:11925 n1 \"'/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\\\"no-delay\\\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11925 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential\" #>  #> ---------------------------------------------------------------------- #> Manually, (i) login into external machine ‘server.remote.org’: #>  #>   '/usr/bin/ssh' -R 11926:localhost:11925 server.remote.org #>  #> and (ii) start worker #2 from there: #>  #>   'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11926 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> Alternatively, start worker #2 from the local machine by combining both steps in a single call: #>  #>   '/usr/bin/ssh' -R 11926:localhost:11925 server.remote.org \"'Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\\\"no-delay\\\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11926 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential\" #>  cl <- c(cl1, cl2) #> Warning: The combined cluster contains 3 duplicated nodes print(cl) #> Socket cluster with 4 nodes where 4 nodes are on host ‘NA’ (R version and platform not queried)"},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"Registers finalizer cluster cluster stopped garbage collected","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"","code":"autoStopCluster(cl, debug = FALSE)"},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"cl cluster object created instance makeClusterPSOCK() parallel::makeCluster(). debug TRUE, debug messages produced cluster garbage collected.","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"cluster object attribute gcMe set.","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"cluster stopped using stopCluster(cl). alternative explicitly call function existing cluster object, create cluster object using makeClusterPSOCK() argument autoStop = TRUE.","code":""},{"path":"https://parallelly.futureverse.org/reference/autoStopCluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automatically Stop a Cluster when Garbage Collected — autoStopCluster","text":"","code":"cl <- makeClusterPSOCK(2, dryrun = TRUE) #> ---------------------------------------------------------------------- #> Manually, start worker #1 on local machine ‘localhost’ with: #>  #>   '/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11873 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  #> ---------------------------------------------------------------------- #> Manually, start worker #2 on local machine ‘localhost’ with: #>  #>   '/home/henrik/shared/software/CBI/_ubuntu22_04/R-4.5.0-gcc11/lib/R/bin/Rscript' --default-packages=datasets,utils,grDevices,graphics,stats,methods -e 'options(socketOptions=\"no-delay\")' -e 'workRSOCK<-tryCatch(parallel:::.workRSOCK,error=function(e)parallel:::.slaveRSOCK);workRSOCK()' MASTER=localhost PORT=11873 OUT=/dev/null TIMEOUT=2592000 XDR=FALSE SETUPTIMEOUT=120 SETUPSTRATEGY=sequential #>  cl <- autoStopCluster(cl) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host ‘NA’ (R version and platform not queried). This cluster is registered to be automatically stopped by the garbage collector rm(list = \"cl\") gc() #>           used (Mb) gc trigger  (Mb) max used  (Mb) #> Ncells 1017215 54.4    1973137 105.4  1973137 105.4 #> Vcells 1885654 14.4    8388608  64.0  2628805  20.1"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of Available and Free Connections — availableConnections","title":"Number of Available and Free Connections — availableConnections","text":"number connections can open time R typically 128, first three occupied always open stdin(), stdout(), stderr() connections, leaves 125 slots available types connections.  Connections used many places, e.g. reading writing file, downloading URLs, communicating parallel R processes socket connections (e.g. parallel::makeCluster() makeClusterPSOCK()), capturing standard output via text connections (e.g. utils::capture.output()).","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of Available and Free Connections — availableConnections","text":"","code":"availableConnections()  freeConnections()"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of Available and Free Connections — availableConnections","text":"non-negative integer, +Inf available number connections greater 16384, limit set via option parallelly.availableConnections.tries.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"how-to-increase-the-limit","dir":"Reference","previous_headings":"","what":"How to increase the limit","title":"Number of Available and Free Connections — availableConnections","text":"R (>= 4.4.0), possible increase limit 128 connections greater number via command-line option --max-connections=N, e.g.   R (< 4.4.0), limit can changed rebuilding R source, limited hardcoded   src/main/connections.c.","code":"$ Rscript -e \"parallelly::availableConnections()\" [1] 128  $ Rscript --max-connections=512 -e \"parallelly::availableConnections()\" [1] 512 #define NCONNECTIONS 128"},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"how-the-limit-is-identified","dir":"Reference","previous_headings":"","what":"How the limit is identified","title":"Number of Available and Free Connections — availableConnections","text":"Since limit might changed, instance custom R builds future releases R, want assume limit 128 R installation.  Unfortunately, possible query R limit . Instead, availableConnections() infers trial--error. fails.  efficiency, result memoized throughout current R session.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Number of Available and Free Connections — availableConnections","text":"'WISH: Increase limit maximum number open connections (currently 125+3)', 2016-07-09, https://github.com/HenrikBengtsson/Wishlist--R/issues/28","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableConnections.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Number of Available and Free Connections — availableConnections","text":"","code":"total <- availableConnections() message(\"You can have \", total, \" connections open in this R installation\") #> You can have 128 connections open in this R installation free <- freeConnections() message(\"There are \", free, \" connections remaining\") #> There are 124 connections remaining"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Number of Available Cores on The Current Machine — availableCores","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"current/main R session counts one, meaning minimum number cores available always least one.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"","code":"availableCores(   constraints = NULL,   methods = getOption2(\"parallelly.availableCores.methods\", c(\"system\",     \"/proc/self/status\", \"cgroups.cpuset\", \"cgroups.cpuquota\", \"cgroups2.cpu.max\",     \"nproc\", \"mc.cores\", \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"Bioconductor\", \"LSF\",     \"PJM\", \"PBS\", \"SGE\", \"Slurm\", \"fallback\", \"custom\")),   na.rm = TRUE,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = c(current = 1L),   which = c(\"min\", \"max\", \"all\"),   omit = getOption2(\"parallelly.availableCores.omit\", 0L) )"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"constraints optional character specifying constraints (\"purposes\") requesting values. instance, systems multicore processing supported (.e. Windows), using constraints = \"multicore\" force single core reported. Using constraints = \"connections\", append \"connections\" methods argument. possible specify multiple constraints, e.g. constraints = c(\"connections\", \"multicore\"). methods character vector specifying infer number available cores. na.rm TRUE, non-missing settings considered/returned. logical Passed detectCores(logical = logical), , supported, returns number logical CPUs (TRUE) physical CPUs/cores (FALSE). least R 4.2.2, detectCores() argument Linux. argument argument methods includes \"system\". default default number cores return non-missing settings available. character specifying settings return. \"min\" (default), minimum value returned. \"max\", maximum value returned (careful!) \"\", values returned. omit (integer; non-negative) Number cores include.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"Return positive (>= 1) integer. = \"\", one value may returned. Together na.rm = FALSE missing values may also returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"following settings (\"methods\") inferring number cores supported: \"system\" - Query detectCores(logical = logical). \"/proc/self/status\" - Query Cpus_allowed_list /proc/self/status. \"cgroups.cpuset\" - Unix, query control group (cgroup v1) value cpuset.set. \"cgroups.cpuquota\" - Unix, query control group (cgroup v1) value cpu.cfs_quota_us / cpu.cfs_period_us. \"cgroups2.cpu.max\" - Unix, query control group (cgroup v2) values cpu.max. \"nproc\" - Unix, query system command nproc. \"mc.cores\" - available, returns value option mc.cores. Note mc.cores defined number additional R processes can used addition main R process.  means mc.cores = 0 calculations done main R process, .e. exactly one core available calculations. mc.cores option defaults environment variable MC_CORES (set accordingly parallel package loaded).  mc.cores option used instance mclapply() parallel package. \"connections\" - Query current number available R connections per freeConnections().  maximum number socket-based parallel cluster nodes possible launch, one needs R connection. exception freeConnections() zero, 1L still returned, availableCores() always return positive integer. \"BiocParallel\" - Query environment variable BIOCPARALLEL_WORKER_NUMBER (integer), defined used BiocParallel (>= 1.27.2). former set, number cores considered. \"_R_CHECK_LIMIT_CORES_\" - Query environment variable _R_CHECK_LIMIT_CORES_ (logical \"warn\") used R CMD check set true R CMD check ---cran. set non-false value, maximum 2 cores considered. \"Bioconductor\" - Query environment variable IS_BIOC_BUILD_MACHINE (logical) used Bioconductor (>= 3.16) build check system. set true, maximum 4 cores considered. \"LSF\" - Query Platform Load Sharing Facility (LSF)/OpenLava environment variable LSB_DJOB_NUMPROC. Jobs multiple (CPU) slots can submitted LSF using bsub -n 2 -R \"span[hosts=1]\" < hello.sh. \"PJM\" - Query Fujitsu Technical Computing Suite (choose shorten \"PJM\") environment variables PJM_VNODE_CORE PJM_PROC_BY_NODE. first set submitted pjsub -L vnode-core=8 hello.sh. \"PBS\" - Query TORQUE/PBS environment variables PBS_NUM_PPN NCPUS. Depending PBS system configuration, resource parameters may may default one. example job submission results qsub -l nodes=1:ppn=2, requests one node two cores. \"SGE\" - Query \"Grid Engine\" scheduler environment variable NSLOTS. example job submission results qsub -pe smp 2 (qsub -pe by_node 2), requests two cores single machine. Known Grid Engine schedulers Oracle Grid Engine (OGE; acquired Sun Microsystems 2010), Univa Grid Engine (UGE; fork open-source SGE 6.2u5), Altair Grid Engine (AGE; acquires Univa Corporation 2020), Son Grid Engine (SGE aka SoGE; open-source fork SGE 6.2u5), \"Slurm\" - Query Simple Linux Utility Resource Management (Slurm) environment variable SLURM_CPUS_PER_TASK. may may set.  can set submitting job, e.g. sbatch --cpus-per-task=2 hello.sh adding #SBATCH --cpus-per-task=2 hello.sh script. SLURM_CPUS_PER_TASK set, fall back use SLURM_CPUS_ON_NODE job single-node job (SLURM_JOB_NUM_NODES 1), e.g. sbatch --ntasks=2 hello.sh. make sure tasks assign single node, specify --nodes=1, e.g. sbatch --nodes=1 --ntasks=16 hello.sh. \"custom\" - option parallelly.availableCores.custom set function, function called (without arguments) value coerced integer, interpreted number available cores.  value NA, ignored. safe custom function call availableCores(); done, custom function recursively called. value methods element, R option name queried.  set, system environment variable queried.  neither set, missing value returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"avoid-ending-up-with-zero-cores","dir":"Reference","previous_headings":"","what":"Avoid ending up with zero cores","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"Note machines might limited number cores, R process runs container cgroup provides small number cores.  cases:   may return zero, often intended likely give error downstream.  Instead, use:   put aside one cores used.  Regardless many cores put aside, function guaranteed return least one core.","code":"ncores <- availableCores() - 1 ncores <- availableCores(omit = 1)"},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"advanced-usage","dir":"Reference","previous_headings":"","what":"Advanced usage","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"possible override maximum number cores machine reported availableCores(methods = \"system\").  can done first specifying options(parallelly.availableCores.methods = \"mc.cores\") number cores use, e.g. options(mc.cores = 8).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableCores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Number of Available Cores on The Current Machine — availableCores","text":"","code":"message(paste(\"Number of cores available:\", availableCores())) #> Number of cores available: 8  if (FALSE) { # \\dontrun{ options(mc.cores = 2L) message(paste(\"Number of cores available:\", availableCores())) } # }  if (FALSE) { # \\dontrun{ ## IMPORTANT: availableCores() may return 1L options(mc.cores = 1L) ncores <- availableCores() - 1      ## ncores = 0 ncores <- availableCores(omit = 1)  ## ncores = 1 message(paste(\"Number of cores to use:\", ncores)) } # }  if (FALSE) { # \\dontrun{ ## Use 75% of the cores on the system but never more than four options(parallelly.availableCores.custom = function() {   ncores <- max(parallel::detectCores(), 1L, na.rm = TRUE)   ncores <- min(as.integer(0.75 * ncores), 4L)   max(1L, ncores) }) message(paste(\"Number of cores available:\", availableCores()))  ## Use 50% of the cores according to availableCores(), e.g. ## allocated by a job scheduler or cgroups. ## Note that it is safe to call availableCores() here. options(parallelly.availableCores.custom = function() {   0.50 * parallelly::availableCores() }) message(paste(\"Number of cores available:\", availableCores())) } # }"},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Set of Available Workers — availableWorkers","title":"Get Set of Available Workers — availableWorkers","text":"Get Set Available Workers","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Set of Available Workers — availableWorkers","text":"","code":"availableWorkers(   constraints = NULL,   methods = getOption2(\"parallelly.availableWorkers.methods\", c(\"mc.cores\",     \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"Bioconductor\", \"LSF\", \"PJM\", \"PBS\", \"SGE\",     \"Slurm\", \"custom\", \"cgroups.cpuset\", \"cgroups.cpuquota\", \"cgroups2.cpu.max\", \"nproc\",     \"system\", \"fallback\")),   na.rm = TRUE,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = getOption2(\"parallelly.localhost.hostname\", \"localhost\"),   which = c(\"auto\", \"min\", \"max\", \"all\") )"},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Set of Available Workers — availableWorkers","text":"constraints optional character specifying constraints (\"purposes\") requesting values. Using constraints = \"connections\", append \"connections\" methods argument. methods character vector specifying infer number available cores. na.rm TRUE, non-missing settings considered/returned. logical Passed -availableCores(). default default set workers. character specifying set / sets return. \"auto\" (default), first non-empty set found. \"min\", minimum value returned. \"max\", maximum value returned (careful!) \"\", values returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Set of Available Workers — availableWorkers","text":"Return character vector workers, typically consists names machines / compute nodes, may also IP numbers.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get Set of Available Workers — availableWorkers","text":"default set workers method rep(\"localhost\", times = availableCores(methods = method, logical = logical)), means least use many parallel workers current machine availableCores() allows method. addition, following settings (\"methods\") also acknowledged: \"LSF\" - Query Platform Load Sharing Facility (LSF)/OpenLava environment variable LSB_HOSTS. \"PJM\" - Query Fujitsu Technical Computing Suite (choose shorten \"PJM\") hostname file given environment variable PJM_O_NODEINF. PJM_O_NODEINF file lists hostnames nodes allotted. function returns hostnames repeated availableCores() times, availableCores() reflects PJM_VNODE_CORE. example, pjsub -L vnode=2 -L vnode-core=8 hello.sh, PJM_O_NODEINF file gives two hostnames, PJM_VNODE_CORE gives eight cores per host, resulting character vector 16 hostnames (two unique hostnames). \"PBS\" - Query TORQUE/PBS environment variable PBS_NODEFILE. set specifies existing file, set workers read file, one worker (node) given per line. example job submission results qsub -l nodes=4:ppn=2, requests four nodes two cores. \"SGE\" - Query \"Grid Engine\" scheduler environment variable PE_HOSTFILE. example job submission results qsub -pe mpi 8 (qsub -pe ompi 8), requests eight cores number machines. Known Grid Engine schedulers Oracle Grid Engine (OGE; acquired Sun Microsystems 2010), Univa Grid Engine (UGE; fork open-source SGE 6.2u5), Altair Grid Engine (AGE; acquires Univa Corporation 2020), Son Grid Engine (SGE aka SoGE; open-source fork SGE 6.2u5), \"Slurm\" - Query Slurm environment variable SLURM_JOB_NODELIST (fallback legacy SLURM_NODELIST) parse set nodes. query Slurm environment variable SLURM_JOB_CPUS_PER_NODE (fallback SLURM_TASKS_PER_NODE) infer many CPU cores Slurm allotted nodes.  SLURM_CPUS_PER_TASK set, always scalar, respected , .e. smaller, used nodes. example, SLURM_NODELIST=\"n1,n[03-05]\" (expands c(\"n1\", \"n03\", \"n04\", \"n05\")) SLURM_JOB_CPUS_PER_NODE=\"2(x2),3,2\" (expands c(2, 2, 3, 2)), c(\"n1\", \"n1\", \"n03\", \"n03\", \"n04\", \"n04\", \"n04\", \"n05\", \"n05\") returned.  addition, SLURM_CPUS_PER_TASK=1, can happen depending hyperthreading configurations Slurm cluster, c(\"n1\", \"n03\", \"n04\", \"n05\") returned. \"custom\" - option parallelly.availableWorkers.custom set function, function called (without arguments) value coerced character vector, interpreted hostnames available workers. safe custom function call availableWorkers(); done, custom function recursively called.","code":""},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"known-limitations","dir":"Reference","previous_headings":"","what":"Known limitations","title":"Get Set of Available Workers — availableWorkers","text":"availableWorkers(methods = \"Slurm\") expand SLURM_JOB_NODELIST using scontrol show hostnames \"$SLURM_JOB_NODELIST\", available. available, attempts parse compressed nodelist based best-guess understanding possible syntax may . One known limitation \"multi-dimensional\" ranges supported, e.g. \"[1-2]b[3-4]\" expanded scontrol c(\"a1b3\", \"a1b4\", \"a2b3\", \"a2b4\").  scontrol available, components failed parsed dropped informative warning message.  components parsed, result methods = \"Slurm\" empty.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/availableWorkers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Set of Available Workers — availableWorkers","text":"","code":"message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) #> Available workers: ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’, ‘localhost’  if (FALSE) { # \\dontrun{ options(mc.cores = 2L) message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) } # }  if (FALSE) { # \\dontrun{ ## Always use two workers on host 'n1' and one on host 'n2' options(parallelly.availableWorkers.custom = function() {   c(\"n1\", \"n1\", \"n2\") }) message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) } # }  if (FALSE) { # \\dontrun{ ## A 50% random subset of the available workers. ## Note that it is safe to call availableWorkers() here. options(parallelly.availableWorkers.custom = function() {   workers <- parallelly::availableWorkers()   sample(workers, size = 0.50 * length(workers)) }) message(paste(\"Available workers:\",         paste(sQuote(availableWorkers()), collapse = \", \"))) } # }"},{"path":"https://parallelly.futureverse.org/reference/cloneNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Clone one or more nodes — cloneNode","title":"Clone one or more nodes — cloneNode","text":"Clone one nodes","code":""},{"path":"https://parallelly.futureverse.org/reference/cloneNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clone one or more nodes — cloneNode","text":"","code":"cloneNode(x, ...)"},{"path":"https://parallelly.futureverse.org/reference/cloneNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clone one or more nodes — cloneNode","text":"x cluster node cluster. ... Optional arguments overriding recorded ones.","code":""},{"path":"https://parallelly.futureverse.org/reference/cloneNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clone one or more nodes — cloneNode","text":"object class class(x).","code":""},{"path":"https://parallelly.futureverse.org/reference/cloneNode.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clone one or more nodes — cloneNode","text":"","code":"# \\donttest{ cl <- makeClusterPSOCK(2) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host ‘localhost’ (R version 4.5.0 (2025-04-11), platform x86_64-pc-linux-gnu)  ## Terminate the second cluster node parallel::stopCluster(cl[2])  ## Show that cluster node #2 is no longer alive (wait a bit first) Sys.sleep(1.0) print(isNodeAlive(cl)) #> [1]  TRUE FALSE print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host ‘localhost’ (R version 4.5.0 (2025-04-11), platform x86_64-pc-linux-gnu). 1 node (#2) has a broken connection (ERROR: invalid connection)  ## \"Restart\" it cl[2] <- cloneNode(cl[2]) print(cl) #> Socket cluster with 2 nodes where 2 nodes are on host ‘localhost’ (R version 4.5.0 (2025-04-11), platform x86_64-pc-linux-gnu)  ## Check all nodes print(isNodeAlive(cl)) #> [1] TRUE TRUE # }"},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Recent CPU Load — cpuLoad","title":"Get the Recent CPU Load — cpuLoad","text":"Get Recent CPU Load","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Recent CPU Load — cpuLoad","text":"","code":"cpuLoad()"},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Recent CPU Load — cpuLoad","text":"named numeric vector three elements 1min, 5min, 15min non-negative values. values represent estimates CPU load last minute, last five minutes, last fifteen minutes [1]. idle system values close zero, heavily loaded system values near parallel::detectCores(). unknown, missing values returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the Recent CPU Load — cpuLoad","text":"function works Unix-like system /proc/loadavg.","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Get the Recent CPU Load — cpuLoad","text":"Linux Load Averages: Solving Mystery, Brendan Gregg's Blog, 2017-08-08, https://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html","code":""},{"path":"https://parallelly.futureverse.org/reference/cpuLoad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Recent CPU Load — cpuLoad","text":"","code":"loadavg <- cpuLoad() print(loadavg) #>  1min  5min 15min  #>  0.64  0.60  0.56"},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for SSH clients on the current system — find_rshcmd","title":"Search for SSH clients on the current system — find_rshcmd","text":"Search SSH clients current system","code":""},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for SSH clients on the current system — find_rshcmd","text":"","code":"find_rshcmd(which = NULL, first = FALSE, must_work = TRUE)"},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for SSH clients on the current system — find_rshcmd","text":"character vector specifying types SSH clients search .  NULL, default set clients supported current platform searched . first TRUE, first client found returned, otherwise located clients returned. must_work TRUE clients found, error produced, otherwise warning.","code":""},{"path":"https://parallelly.futureverse.org/reference/find_rshcmd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for SSH clients on the current system — find_rshcmd","text":"named list pathnames located SSH clients. pathnames may followed zero command-line options, .e. elements returned list character vectors length one . first = TRUE, first one returned. Attribute version contains output querying executable version (via command-line option -V).","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the Average Number of Free CPU Cores — freeCores","title":"Get the Average Number of Free CPU Cores — freeCores","text":"Get Average Number Free CPU Cores","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the Average Number of Free CPU Cores — freeCores","text":"","code":"freeCores(   memory = c(\"5min\", \"15min\", \"1min\"),   fraction = 0.9,   logical = getOption2(\"parallelly.availableCores.logical\", TRUE),   default = parallelly::availableCores() )"},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the Average Number of Free CPU Cores — freeCores","text":"memory (character) time period used infer system load, alternatives 5 minutes (default), 15 minutes, 1 minute. fraction (non-negative numeric) scale factor. logical Passed -availableCores(). default (integer) value returned system load unknown, .e. cpuLoad() return missing values.","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the Average Number of Free CPU Cores — freeCores","text":"positive integer attributes loadavg (named numeric), maxCores (named integer), argument memory (character), argument fraction (numeric).","code":""},{"path":"https://parallelly.futureverse.org/reference/freeCores.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the Average Number of Free CPU Cores — freeCores","text":"","code":"free <- freeCores() print(free) #> [1] 6 #> attr(,\"loadavg\") #>  1min  5min 15min  #>  0.64  0.60  0.56  #> attr(,\"maxCores\") #> system  #>      8  #> attr(,\"memory\") #> [1] \"5min\" #> attr(,\"fraction\") #> [1] 0.9  if (FALSE) { # \\dontrun{ ## Make availableCores() agile to the system load options(parallelly.availableCores.custom = function() freeCores()) } # }"},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a TCP port that can be opened — freePort","title":"Find a TCP port that can be opened — freePort","text":"Find TCP port can opened","code":""},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a TCP port that can be opened — freePort","text":"","code":"freePort(ports = 1024:65535, default = \"random\", randomize = TRUE)"},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a TCP port that can be opened — freePort","text":"ports (integer vector, character string) Zero TCP ports [0, 65535] scan. \"random\", random set ports considered. \"auto\", port given environment variable R_PARALLEL_PORT used, may also specify random. default (integer) NA_integer_ port returned available port found. \"first\", ports[1].  \"random\", random port among ports used. length(ports) == 0, NA_integer_. randomize (logical) TRUE, ports randomly shuffled searched.  shuffle forward RNG seed.","code":""},{"path":"https://parallelly.futureverse.org/reference/freePort.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a TCP port that can be opened — freePort","text":"Returns integer representing first port among ports can opened.  none can opened, default returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks if a Connection is Valid — isConnectionValid","title":"Checks if a Connection is Valid — isConnectionValid","text":"Get unique identifier R connection check whether connection still valid.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks if a Connection is Valid — isConnectionValid","text":"","code":"isConnectionValid(con)  connectionId(con)"},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks if a Connection is Valid — isConnectionValid","text":"con connection.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks if a Connection is Valid — isConnectionValid","text":"isConnectionValid() returns TRUE connection still valid, otherwise FALSE.  FALSE, character attribute reason provides explanation connection valid. connectionId() returns non-negative integer, -1, NA_integer_. connections stdin, stdout, stderr, 0, 1, 2, returned, respectively.  connections, integer greater equal 3 based connection's internal pointer returned. connection serialized, longer valid, identifier -1. Attribute raw_id returns pointer string inferred.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"connection-index-versus-connection-identifier","dir":"Reference","previous_headings":"","what":"Connection Index versus Connection Identifier","title":"Checks if a Connection is Valid — isConnectionValid","text":"R represents connections indices using plain integers, e.g. idx <- .integer(con). three connections standard input (\"stdin\"), standard output (\"stdout\"), standard error (\"stderr\") always exists indices 0, 1, 2. connection opened beyond get index three greater, depending availability given base::showConnections(). get connection given index, use base::getConnection(). Unfortunately, index representation connections non-robust, e.g. cases two 'connection' objects can end index used, written output may end wrong destination files database might get corrupted.  can instance happen base::closeAllConnections() used (*). contrast, id <- connectionId(con) gives identifier unique 'connection' object.  identifier based internal pointer address object.  risk two connections R session end pointer address small. Thus, case ended situation two connections con1 con2 share index—.integer(con1) == .integer(con2)— never share identifier— connectionId(con1) != connectionId(con2). , isConnectionValid() can used check one connections, , valid. (*) Note good reason calling closeAllConnections() called, great risk files get corrupted etc. See (1) examples details problem. think need use , much safer restart R guaranteed give working R session non-clashing connections. might also closeAllConnections() used base::sys.save.image() called, might happen R forced terminate.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"connections-cannot-be-serialized-or-saved","dir":"Reference","previous_headings":"","what":"Connections Cannot be Serialized Or Saved","title":"Checks if a Connection is Valid — isConnectionValid","text":"'connection' serialized, e.g. saved file read used another R session.  attempted, connection valid.  problem may occur parallel processing passing R object parallel worker processing, e.g. exported object may hold internal database connection longer valid worker. connection serialized, internal pointer address invalidated (set nil). cases, connectionId(con) returns -1 isConnectionValid(con) returns FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Checks if a Connection is Valid — isConnectionValid","text":"'BUG: connection object may become corrupt re-referenced another connection (PATCH)', 2018-10-30. R-devel thread PATCH: Asserting 'connection' used changed + R_GetConnection2(), 2018-10-31.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/isConnectionValid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Checks if a Connection is Valid — isConnectionValid","text":"","code":"## R represents connections as plain indices as.integer(stdin())          ## int 0 #> [1] 0 as.integer(stdout())         ## int 1 #> [1] 3 as.integer(stderr())         ## int 2 #> [1] 2  ## The first three connections always exist and are always valid isConnectionValid(stdin())   ## TRUE #> [1] TRUE connectionId(stdin())        ## 0L #> [1] 0 isConnectionValid(stdout())  ## TRUE #> [1] FALSE #> attr(,\"reason\") #> [1] \"Connection (connection: index=3, description=\\\"\\\", class=\\\"file\\\", mode=\\\"w+b\\\", text=\\\"binary\\\", opened=\\\"opened\\\", can read=\\\"yes\\\", can write=\\\"yes\\\", id=NA) is no longer valid. It differ from the currently registered R connection with the same index 3 (connection: index=3, description=\\\"\\\", class=\\\"file\\\", mode=\\\"w+b\\\", text=\\\"binary\\\", opened=\\\"opened\\\", can read=\\\"yes\\\", can write=\\\"yes\\\", id=1359, raw_id=\\\"<pointer: 0x54f>\\\")\" connectionId(stdout())       ## 1L #> [1] NA isConnectionValid(stderr())  ## TRUE #> [1] TRUE connectionId(stderr())       ## 2L #> [1] 2  ## Connections cannot be serialized con <- file(tempfile(), open = \"w\") x <- list(value = 42, stderr = stderr(), con = con) y <- unserialize(serialize(x, connection = NULL)) isConnectionValid(y$stderr)  ## TRUE #> [1] TRUE connectionId(y$stderr)       ##  2L #> [1] 2 isConnectionValid(y$con)     ## FALSE with attribute 'reason' #> [1] FALSE #> attr(,\"reason\") #> [1] \"Connection (connection: index=6, description=\\\"/tmp/henrik/Rtmph11WgZ/fileec90422aa85bf\\\", class=\\\"file\\\", mode=\\\"w\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=-1) is no longer valid. It differ from the currently registered R connection with the same index 6 (connection: index=6, description=\\\"/tmp/henrik/Rtmph11WgZ/fileec90422aa85bf\\\", class=\\\"file\\\", mode=\\\"w\\\", text=\\\"text\\\", opened=\\\"opened\\\", can read=\\\"no\\\", can write=\\\"yes\\\", id=1361, raw_id=\\\"<pointer: 0x551>\\\")\" connectionId(y$con)          ## -1L #> [1] -1 close(con)"},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not we are running in a forked child process — isForkedChild","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"Checks whether running forked child process","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"","code":"isForkedChild()"},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"(logical) Returns TRUE running forked child process, otherwise FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedChild.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks whether or not we are running in a forked child process — isForkedChild","text":"Examples setups functions rely forked parallelization parallel::makeCluster(n, type = \"FORK\"), parallel::mclapply(), future::plan(\"multicore\").","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"Checks whether Cluster Node Runs Forked Process","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"","code":"isForkedNode(node, ...)"},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"node cluster node class SOCKnode SOCK0node. ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isForkedNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not a Cluster Node Runs in a Forked Process — isForkedNode","text":"(logical) Returns TRUE cluster node running forked child process FALSE . inferred, NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"Checks whether Cluster Node Runs Localhost","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"","code":"isLocalhostNode(node, ...)"},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"node cluster node class SOCKnode SOCK0node. ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isLocalhostNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks whether or not a Cluster Node Runs on Localhost — isLocalhostNode","text":"(logical) Returns TRUE cluster node running current machine FALSE runs another machine. inferred, NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether or not the cluster nodes are alive — isNodeAlive","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"Check whether cluster nodes alive","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"","code":"isNodeAlive(x, ...)"},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"x cluster cluster node (\"worker\"). ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"logical vector length length(x) values FALSE, TRUE, NA.  can established process cluster node running, TRUE returned. run, FALSE returned. neither can inferred, times , NA returned.","code":""},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"function works checking whether cluster node process running .  done querying system process ID (PID), registered makeClusterPSOCK() node starts. PID known, NA returned. Unix macOS, PID queried using tools::pskill() fallback system(\"ps\"). MS Windows, system2(\"tasklist\") used, may take long time lot processes running. details, see internal pid_exists() function.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/isNodeAlive.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check whether or not the cluster nodes are alive — isNodeAlive","text":"","code":"# \\donttest{ cl <- makeClusterPSOCK(2)  ## Check if cluster node #2 is alive print(isNodeAlive(cl[[2]])) #> [1] TRUE  ## Check all nodes print(isNodeAlive(cl)) #> [1] TRUE TRUE # }"},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":null,"dir":"Reference","previous_headings":"","what":"Terminate one or more cluster nodes using process signaling — killNode","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"Terminate one cluster nodes using process signaling","code":""},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"","code":"killNode(x, signal = tools::SIGTERM, ...)"},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"x cluster cluster node terminate. signal integer specifies signal level sent parallel R process. tools::SIGINT (2) tools::SIGTERM (15) supported operating systems (.e. Unix, macOS, MS Windows). signals platform specific, cf. tools::pskill(). ... used.","code":""},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"TRUE signal successfully applied, FALSE , NA signaling supported specific cluster node. Warning: R (< 3.5.0), NA always returned. due bug R (< 3.5.0), signaling result trusted.","code":""},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"Note preferred way terminate cluster via parallel::stopCluster(), terminates cluster nodes kindly asking nicely shut . Using killNode() much sever approach. abruptly terminates underlying R process, possibly without giving parallel worker chance terminate gracefully.  example, might get terminated middle writing file. tools::pskill() used send signal R process hosting parallel worker.","code":""},{"path":"https://parallelly.futureverse.org/reference/killNode.html","id":"known-limitations","dir":"Reference","previous_headings":"","what":"Known limitations","title":"Terminate one or more cluster nodes using process signaling — killNode","text":"function works cluster nodes class RichSOCKnode, created makeClusterPSOCK().  work using parallel::makeCluster() friends. Currently, possible send signals parallel workers, , cluster nodes, run local machine. attempted use killNode() remote parallel workers, NA returned informative warning produced.","code":""},{"path":[]},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"makeClusterMPI() function creates MPI cluster R workers parallel processing.  function utilizes makeCluster(..., type = \"MPI\") parallel package tweaks cluster attempt avoid stopCluster() hanging (1). WARNING: function much beta version used parallel::makeCluster(..., type = \"MPI\") fails.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"","code":"makeClusterMPI(   workers,   ...,   autoStop = FALSE,   verbose = isTRUE(getOption(\"parallelly.debug\")) )"},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"workers number workers (positive integer). autoStop TRUE, cluster automatically stopped using stopCluster() garbage collected, unless already stopped.  See also autoStopCluster(). verbose TRUE, informative messages outputted. ... Optional arguments passed makeCluster(workers, type = \"MPI\", ...).","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"object class c(\"RichMPIcluster\", \"MPIcluster\", \"cluster\") consisting list \"MPInode\" workers.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"Creating MPI clusters requires Rmpi snow packages installed.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"alternative-usage","dir":"Reference","previous_headings":"","what":"Alternative usage","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"R (>= 4.4.0), alternatively using cl <- parallelly::makeClusterMPI(workers) :","code":"cl <- parallel::makeCluster(workers, type = parallelly::MPI)"},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"R-sig-hpc thread Rmpi: mpi.close.Rslaves() 'hangs' 2017-09-28.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/makeClusterMPI.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Rich Message Passing Interface (MPI) Cluster of R Workers for Parallel Processing — makeClusterMPI","text":"","code":"if (FALSE) { # \\dontrun{ if (requireNamespace(\"Rmpi\") && requireNamespace(\"snow\")) {   cl <- makeClusterMPI(2, autoStop = TRUE)   print(cl)   y <- parLapply(cl, X = 1:3, fun = sqrt)   print(y)   rm(list = \"cl\") } } # }"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"makeClusterPSOCK() function creates cluster R workers parallel processing.  R workers may background R sessions current machine, R sessions external machines (local remote), mix . external workers, default use SSH connect external machines.  function works similarly makePSOCKcluster() parallel package, provides additional flexibility options controlling setup system calls launch background R workers, connect external machines.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"","code":"makeClusterPSOCK(   workers,   makeNode = makeNodePSOCK,   port = c(\"auto\", \"random\"),   user = NULL,   ...,   autoStop = FALSE,   tries = getOption2(\"parallelly.makeNodePSOCK.tries\", 3L),   delay = getOption2(\"parallelly.makeNodePSOCK.tries.delay\", 15),   validate = getOption2(\"parallelly.makeNodePSOCK.validate\", TRUE),   verbose = isTRUE(getOption(\"parallelly.debug\")) )  makeNodePSOCK(   worker = getOption2(\"parallelly.localhost.hostname\", \"localhost\"),   master = NULL,   port,   connectTimeout = getOption2(\"parallelly.makeNodePSOCK.connectTimeout\", 2 * 60),   timeout = getOption2(\"parallelly.makeNodePSOCK.timeout\", 30 * 24 * 60 * 60),   rscript = NULL,   homogeneous = NULL,   rscript_args = NULL,   rscript_envs = NULL,   rscript_libs = NULL,   rscript_startup = NULL,   rscript_sh = c(\"auto\", \"cmd\", \"sh\", \"none\"),   default_packages = c(\"datasets\", \"utils\", \"grDevices\", \"graphics\", \"stats\", if     (methods) \"methods\"),   methods = TRUE,   socketOptions = getOption2(\"parallelly.makeNodePSOCK.socketOptions\", \"no-delay\"),   useXDR = getOption2(\"parallelly.makeNodePSOCK.useXDR\", FALSE),   outfile = \"/dev/null\",   renice = NA_integer_,   rshcmd = getOption2(\"parallelly.makeNodePSOCK.rshcmd\", NULL),   user = NULL,   revtunnel = NA,   rshlogfile = NULL,   rshopts = getOption2(\"parallelly.makeNodePSOCK.rshopts\", NULL),   rank = 1L,   manual = FALSE,   dryrun = FALSE,   quiet = FALSE,   setup_strategy = getOption2(\"parallelly.makeNodePSOCK.setup_strategy\", \"parallel\"),   action = c(\"launch\", \"options\"),   verbose = FALSE )"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"workers hostnames workers (character vector) number localhost workers (positive integer). makeNode function creates \"SOCKnode\" \"SOCK0node\" object, represents connection worker. port port number master used communicating workers (via socket connections).  integer vector ports, random one among chosen.  \"random\", random port chosen 11000:11999, range specified environment variable R_PARALLELLY_RANDOM_PORTS. \"auto\" (default), default (single) port taken environment variable R_PARALLEL_PORT, otherwise \"random\" used. Note, use argument specify port number used rshcmd, typically SSH client.  Instead, SSH daemon runs different port default 22, specify SSH port appending hostname, e.g. \"remote.server.org:2200\" via SSH options -p, e.g. rshopts = c(\"-p\", \"2200\"). user (optional) user name used communicating another host. autoStop TRUE, cluster automatically stopped using stopCluster() garbage collected, unless already stopped.  See also autoStopCluster(). tries, delay Maximum number attempts done launch node makeNode() delay (seconds) -attempts. argument port specifies one port, e.g. port = \"random\" random port drawn validated tries times. Arguments tries delay used setup_strategy == \"sequential\". validate TRUE (default), nodes created, validated work inquiring session information, saved attribute session_info node. verbose TRUE, informative messages outputted. worker hostname IP number machine worker run. Attribute localhost can set TRUE FALSE manually indicate whether worker local host. master hostname IP number master / calling machine, known workers.  NULL (default), default Sys.info()[[\"nodename\"]] unless worker localhost revtunnel = TRUE case \"localhost\". connectTimeout maximum time (seconds) allowed socket connection master worker established (defaults 2 minutes). See note current lack support Linux macOS systems. timeout maximum time (seconds) allowed pass without master worker communicate (defaults 30 days). rscript, homogeneous system command launching Rscript worker whether installed path calling machine .  details, see . rscript_args Additional arguments Rscript (character vector).  argument can used customize R environment workers launches. instance, use rscript_args = c(\"-e\", shQuote('setwd(\"/path/\")')) set working directory /path/workers. rscript_envs named character vector environment variables set unset worker startup, e.g. rscript_envs = c(FOO = \"3.14\", \"HOME\", \"UNKNOWN\", UNSETME = NA_character_). element named, value variable used name value value Sys.getenv() variable.  Non-existing environment variables dropped. variables set using Sys.setenv(). named element value NA_character_ cause variable unset, done via Sys.unsetenv(). rscript_libs character vector R library paths used library search path R workers.  asterisk (\"*\") resolved default .libPaths() worker. , prepend folder, instead replacing existing ones, use rscript_libs = c(\"new_folder\", \"*\"). pass non-default library path currently set main R session workers, use rscript_libs = .libPaths(). rscript_startup R expression character vector R code, list mix , evaluated R worker prior launching worker's event loop. instance, use rscript_startup = 'setwd(\"/path/\")' set working directory /path/workers. rscript_sh type shell used rscript launched, \"sh\" launched via POSIX shell \"cmd\" launched via MS Windows shell.  controls shell command-line options quoted, also R string expression quoted passed Rscript. \"none\", quoting done. \"auto\" (default), cluster node launched locally, set \"sh\" \"cmd\" according current platform. launched remotely, set \"sh\" based assumption remote machines typically launch commands via SSH POSIX shell. remote machines run MS Windows, use rscript_sh = \"cmd\". length(rscript_sh) two, rscript_sh[1] inner rscript_sh[2] outer shell quoting Rscript call. precisely, rscript_sh[1] Rscript arguments need shell quoting (e.g. Rscript -e \"<expr>\"), rscript_sh[2] whole Rscript ... call. length(rscript_sh) one, used inner outer shell quoting. default_packages character vector NULL controls R packages attached cluster node startup.  asterisk (\"*\") resolves getOption(\"defaultPackages\") current machine. NULL, default set packages R attached. methods TRUE (default), methods package also loaded. argument exists legacy reasons due Rscript worked R (< 3.5.0). socketOptions character string sets R option socketOptions worker. useXDR FALSE (default), communication master workers, binary, use small-endian (faster), otherwise big-endian (\"XDR\"; slower). outfile direct stdout stderr connection output workers. NULL, redirection output done, means output relayed terminal local computer.  Windows, output relayed running R terminal GUI. renice numerical 'niceness' (priority) set worker processes. rshcmd, rshopts command (character vector) run master launch process another host additional arguments (character vector).  arguments applied machine localhost.  details, see . revtunnel TRUE, reverse SSH tunnel set worker worker R process sets socket connection local port (port + rank - 1) reaches master port port. FALSE, worker try connect directly port port master. NA, TRUE FALSE inferred inspection rshcmd[1]. details, see . rshlogfile (optional) filename, output produced rshcmd call logged file, TRUE, logged temporary file.  log file name available attribute part return node object. Warning: works SSH clients support command-line option -E .log`.  example, PuTTY's plink support option, attempts specify rshlogfile cause SSH connection fail. rank unique one-based index worker (automatically set). manual TRUE workers need run manually. command run displayed. dryrun TRUE, nothing set , message suggesting launch worker terminal outputted.  useful troubleshooting. quiet TRUE, output produced using verbose = TRUE. setup_strategy \"parallel\" (default), workers set concurrently, one .  \"sequential\", set sequentially. action internal argument. ... Optional arguments passed makeNode(workers[], ..., rank = ) = seq_along(workers).","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"object class c(\"RichSOCKcluster\", \"SOCKcluster\", \"cluster\") consisting list \"SOCKnode\" \"SOCK0node\" workers (also inherit RichSOCKnode). makeNodePSOCK() returns \"SOCKnode\" \"SOCK0node\" object representing established connection worker.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"alternative-usage","dir":"Reference","previous_headings":"","what":"Alternative usage","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"R (>= 4.5.0), alternatively using cl <- parallelly::makeClusterPSOCK(workers) :   'R' RPSOCK stands \"Rich\", reflects cluster returned class RichSOCKcluster, whereas default class SOCKcluster.","code":"cl <- parallel::makeCluster(workers, type = parallelly::RPSOCK)"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"protection-against-cpu-overuse","dir":"Reference","previous_headings":"","what":"Protection against CPU overuse","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"Using many parallel workers machine may result overusing CPU.  example, R script hard codes number parallel workers 32,   use 100% CPU cores running machine fewer 32 CPU cores.  example, eight-core machine, may run CPU 400% capacity, significant negative effect current R process, also processes running machine.  also problem systems R gets allotted specific number CPU cores, case high-performance compute (HPC) clusters, also shared systems limits user processes via Linux Control Groups (cgroups). example, free account Posit Cloud limited single CPU core. Parallelizing 32 workers access single core, result 3200% overuse 32 concurrent R processes competing single CPU core. protect CPU overuse mistake, makeClusterPSOCK() warn parallelizing 100%;   attempts resulting 300% overuse refused;   See parallelly.options change default thresholds. built-protection can circumvented specifying argument workers AsIs object, e.g. workers = (25) (recommended).","code":"cl <- makeClusterPSOCK(32) cl <- parallelly::makeClusterPSOCK(12, dryrun = TRUE) Warning message: In checkNumberOfLocalWorkers(workers) :   Careful, you are setting up 12 localhost parallel workers with only 8 CPU cores available for this R process (per 'system'), which could result in a 150% load. The soft limit is set to 100%. Overusing the CPUs has negative impact on the current R process, but also on all other processes of yours and others running on the same machine. See help(\"parallelly.maxWorkers.localhost\", package = \"parallelly\") for further explanations and how to override the soft limit that triggered > cl <- parallelly::makeClusterPSOCK(25, dryrun = TRUE) Error in checkNumberOfLocalWorkers(workers) :   Attempting to set up 25 localhost parallel workers with only 8 CPU cores available for this R process (per 'system'), which could result in a 312% load. The hard limit is set to 300%. Overusing the CPUs has negative impact on the current R process, but also on all other processes of yours and others running on the same machine. See help(\"parallelly.maxWorkers.localhost\", package = \"parallelly\") for further explanations and how to override the hard limit that triggered this error"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"definition-of-localhost","dir":"Reference","previous_headings":"","what":"Definition of localhost","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"hostname considered localhost equals: \"localhost\", \"127.0.0.1\", Sys.info()[[\"nodename\"]]. also considered localhost appears line value Sys.info()[[\"nodename\"]] file /etc/hosts.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"default-ssh-client-and-options-arguments-rshcmd-and-rshopts-","dir":"Reference","previous_headings":"","what":"Default SSH client and options (arguments rshcmd and rshopts)","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"Arguments rshcmd rshopts used connecting external host. default method connecting external host via SSH system executable given argument rshcmd.  default given option parallelly.makeNodePSOCK.rshcmd. set, default use ssh Unix-like systems, including macOS well Windows 10.  older MS Windows versions, built-ssh client, default use () plink PuTTY project, (ii) ssh client distributed RStudio. PuTTY puts Windows' system PATH installed, meaning function find PuTTY automatically installed.  , manually set specify PuTTY SSH client, specify absolute pathname plink.exe first element option -ssh second rshcmd = c(\"C:/Path/PuTTY/plink.exe\", \"-ssh\"). elements rshcmd individually \"shell\" quoted element rshcmd[1] must system PATH. Furthermore, running R RStudio Windows, ssh client distributed RStudio also considered. client, MinGW MSYS, searched folder given RSTUDIO_MSYS_SSH environment variable—variable () set running RStudio. use SSH client outside RStudio, set RSTUDIO_MSYS_SSH accordingly. can override default set SSH clients searched specifying argument rshcmd via option parallelly.makeNodePSOCK.rshcmd using format <...>, e.g. rshcmd = c(\"<rstudio-ssh>\", \"<putty-plink>\", \"<ssh>\").  See examples. SSH-client found, informative error message produced. Additional SSH command-line options may specified via argument rshopts, defaults option parallelly.makeNodePSOCK.rshopts. instance, private SSH key can provided rshopts = c(\"-\", \"~/.ssh/my_private_key\").  PuTTY users specify PuTTY PPK file, e.g. rshopts = c(\"-\", \"C:/Users/joe/.ssh/my_keys.ppk\"). Contrary rshcmd, elements rshopts quoted.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"accessing-external-machines-that-prompts-for-a-password","dir":"Reference","previous_headings":"","what":"Accessing external machines that prompts for a password","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"IMPORTANT: one exception, possible functions log launch R workers external machines requires password entered manually authentication. known exception PuTTY client Windows one can pass password via command-line option -pw, e.g. rshopts = c(\"-pw\", \"MySecretPassword\"). Note, depending whether run R terminal via GUI, might even see password prompt.  also likely enter password, connection set via background system call. poor man's workaround setup requires password manually log external machines launch R workers hand. approach, use manual = TRUE follow instructions include cut'n'pasteable commands launch worker external machine. However, much convenient less tedious method set key-based SSH authentication local machine external machine(s), explain .","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"accessing-external-machines-via-key-based-ssh-authentication","dir":"Reference","previous_headings":"","what":"Accessing external machines via key-based SSH authentication","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"best approach automatically launch R workers external machines SSH set key-based SSH authentication.  allow log external machine without enter password. Key-based SSH authentication taken care SSH client R. configure , see manuals SSH client search web \"ssh key authentication\".","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"reverse-ssh-tunneling","dir":"Reference","previous_headings":"","what":"Reverse SSH tunneling","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"SSH used, inferred rshcmd[1], default use reverse SSH tunneling (revtunnel = TRUE), otherwise (revtunnel = FALSE). Using reverse SSH tunneling, avoids complications otherwise configure port forwarding firewalls, often requires static IP address well privileges edit firewall outgoing router, something users . also advantage know internal / public IP address / hostname master. Yet another advantage need DNS lookup worker machines master, may configured disabled systems, e.g. compute clusters.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"argument-rscript","dir":"Reference","previous_headings":"","what":"Argument rscript","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"homogeneous FALSE, rscript defaults \"Rscript\", .e. assumed Rscript executable available PATH worker. homogeneous TRUE, rscript defaults file.path(R.home(\"bin\"), \"Rscript\"), .e. basically assumed worker caller share file system R installation. specified, argument rscript character vector one elements.  asterisk (\"*\") resolved default homogeneous-dependent Rscript path. elements automatically shell quoted using base::shQuote(), except format <ENVVAR>=<VALUE>, , ones matching regular expression '^[[:alpha:]_][[:alnum:]_]*=.*'. Another exception rscript inherits 'AsIs'.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"default-value-of-argument-homogeneous","dir":"Reference","previous_headings":"","what":"Default value of argument homogeneous","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"default value homogeneous TRUE either following fulfilled: worker localhost revtunnel FALSE master localhost worker neither IP number fully qualified domain name (FQDN).  hostname considered FQDN contains one periods cases, homogeneous defaults FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"connection-timeout","dir":"Reference","previous_headings":"","what":"Connection timeout","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"Argument connectTimeout work properly Unix macOS due limitation R .  details , please see R-devel thread 'BUG?: Linux setTimeLimit() fails propagate timeout error occurs (works Windows)' 2016-10-26 (https://stat.ethz.ch/pipermail/r-devel/2016-October/073309.html). used, timeout eventually trigger error, happen socket connection timeout timeout happens.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"communication-timeout","dir":"Reference","previous_headings":"","what":"Communication timeout","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"communication master worker within timeout limit, corresponding socket connection closed automatically.  eventually result error code trying access connection. timeout also terminates stray-running parallel cluster-node process.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"failing-to-set-up-local-workers","dir":"Reference","previous_headings":"","what":"Failing to set up local workers","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"setting cluster localhost workers, , workers running machine master R process, occasionally connection worker (\"cluster node\") may fail set . occurs, informative error message troubleshooting suggestions produced. common reason localhost failures due port clashes.  Retrying often resolve problem. R stalls setting cluster local workers, might virtual private network (VPN) enabled configured prevent connecting localhost.  verify case, call following terminal:   also freezed VPN intercepts connections localhost. happens, try also:   rare cases, 127.0.0.1 might work localhost . latter works, setting R option:   solve (default \"localhost\").  can set automatically R starts adding ~/.Rprofile startup file. Alternatively, set environment variable R_PARALLELLY_LOCALHOST_HOSTNAME=127.0.0.1 ~/.Renviron file. using 127.0.0.1 work around problem, check VPN settings make sure allows connections localhost 127.0.0.1.","code":"{local}$ ssh localhost \"date\" {local}$ ssh 127.0.0.1 \"date\" options(parallelly.localhost.hostname = \"127.0.0.1\")"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"failing-to-set-up-remote-workers","dir":"Reference","previous_headings":"","what":"Failing to set up remote workers","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"cluster remote workers runs R processes external machines. external R processes launched , typically, SSH remote machine.  work, remote machines needs R installed, preferably version main machine.  work, required one can SSH remote machines.  Ideally, SSH connections use authentication based public-private SSH keys set remote workers can fully automated (see ).  makeClusterPSOCK() fails set one remote R workers, informative error message produced. reasons failing set remote workers.  happens, start asserting can SSH remote machine launch Rscript calling something like: confirmed work, confirm can achieve single command-line call; latter assert proper startup configuration also non-interactive shell sessions remote machine. remote machines running MS Windows, make sure add argument rscript_sh = \"cmd\" calling makeClusterPSOCK(), default rscript_sh = \"sh\", assumes remote machines Unix-like machines. Another reason failing setup remote workers running R version compatible version main R session running.  instance, run R (>= 3.6.0) locally workers run R (< 3.5.0), get: Error unserialize(node$con) : error reading connection. R (>= 3.6.0) uses serialization format version 3 default whereas R (< 3.5.0) supports version 2.  can see version R workers adding rscript_args = c(\"-e\", shQuote(\"getRversion()\")) calling makeClusterPSOCK().","code":"{local}$ ssh -l alice remote.server.org {remote}$ Rscript --version R scripting front-end version 4.2.2 (2022-10-31) {remote}$ logout {local}$ {local}$ ssh -l alice remote.server.org Rscript --version R scripting front-end version 4.2.2 (2022-10-31) {local}$"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"for-package-developers","dir":"Reference","previous_headings":"","what":"For package developers","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"creating cluster object, instance via parallel::makeCluster() parallelly::makeClusterPSOCK(), package help example, package vignette, package test, must remember stop cluster end examples(*), vignettes, unit tests. required order leave behind stray parallel cluster workers main R session terminates. Linux macOS, operating system often takes care terminating worker processes forget, MS Windows processes keep running background time , takes 30 days (sic!). R CMD check ---cran indirectly detect stray worker processes MS Windows running R (>= 4.3.0). detected, result placeholder Rscript<hexcode> files left behind temporary directory.  check NOTE look (R (>= 4.3.0)) :   Rscript<hexcode> files background R worker processes, almost always parallel cluster:s forgot stop end.  stop cluster workers, use parallel::stopCluster() end examples(*), vignettes, package tests every cluster object created. (*) Currently, examples excluded detritus checks. validated R-devel revision 82991 (2022-10-02).","code":"* checking for detritus in the temp directory ... NOTE Found the following files/directories:   'Rscript1058267d0c10' 'Rscriptbd4267d0c10'"},{"path":"https://parallelly.futureverse.org/reference/makeClusterPSOCK.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Rich PSOCK Cluster of R Workers for Parallel Processing — makeClusterPSOCK","text":"","code":"## NOTE: Drop 'dryrun = TRUE' below in order to actually connect.  Add ## 'verbose = TRUE' if you run into problems and need to troubleshoot.  ## --------------------------------------------------------------- ## Section 1. Setting up parallel workers on the local machine ## --------------------------------------------------------------- ## EXAMPLE: Two workers on the local machine workers <- c(\"localhost\", \"localhost\") cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)   ## EXAMPLE: Launch 124 workers on MS Windows 10, where half are ## running on CPU Group #0 and half on CPU Group #1.   ## (https://lovickconsulting.com/2021/11/18/ ##  running-r-clusters-on-an-amd-threadripper-3990x-in-windows-10-2/) ## The parallel workers are launched as: ## \"%COMSPEC%\" /c start /B /NODE 1 /AFFINITY 0xFFFFFFFFFFFFFFFE ... ## ... ## \"%COMSPEC%\" /c start /B /NODE 1 /AFFINITY 0xFFFFFFFFFFFFFFFE ...  ## Temporarily disable CPU load protection for this example oopts <- options(parallelly.maxWorkers.localhost = Inf)  ncores <- 124 cpu_groups <- c(0, 1) cl <- lapply(cpu_groups, FUN = function(cpu_group) {     parallelly::makeClusterPSOCK(ncores %/% length(cpu_groups),       rscript = I(c(         Sys.getenv(\"COMSPEC\"), \"/c\", \"start\", \"/B\",         \"/NODE\", cpu_group, \"/AFFINITY\", \"0xFFFFFFFFFFFFFFFE\",         \"*\"       )),       dryrun = TRUE, quiet = TRUE     ) }) ## merge the two 62-node clusters into one with 124 nodes cl <- do.call(c, cl) #> Warning: The combined cluster contains 123 duplicated nodes  ## Re-enable CPU load protection options(oopts)   ## --------------------------------------------------------------- ## Section 2. Setting up parallel workers on remote machines ## --------------------------------------------------------------- ## EXAMPLE: Three remote workers ## Setup of three R workers on two remote machines are set up ## The parallel workers are launched as: ## '/usr/bin/ssh' -R 11058:localhost:11058 n1.remote.org ... ## '/usr/bin/ssh' -R 11059:localhost:11058 n2.remote.org ... ## '/usr/bin/ssh' -R 11060:localhost:11058 n1.remote.org ... workers <- c(\"n1.remote.org\", \"n2.remote.org\", \"n1.remote.org\") cl <- makeClusterPSOCK(workers, dryrun = TRUE, quiet = TRUE)   ## EXAMPLE: Two remote workers running on MS Windows.  Because the ## remote workers are MS Windows machines, we need to use ## rscript_sh = \"cmd\". ## The parallel workers are launched as: ## '/usr/bin/ssh' -R 11912:localhost:11912 mswin1.remote.org ... ## '/usr/bin/ssh' -R 11913:localhost:11912 mswin2.remote.org ... workers <- c(\"mswin1.remote.org\", \"mswin2.remote.org\") cl <- makeClusterPSOCK(workers, rscript_sh = \"cmd\", dryrun = TRUE, quiet = TRUE)   ## EXAMPLE: Local and remote workers ## Same setup when the two machines are on the local network and ## have identical software setups cl <- makeClusterPSOCK(   workers,   revtunnel = FALSE, homogeneous = TRUE,   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Three remote workers 'n1', 'n2', and 'n3' that can only be ## accessed via jumphost 'login.remote.org' ## The parallel workers are launched as: ## '/usr/bin/ssh' -R 11226:localhost:11226 -J login.remote.org n1 ... ## '/usr/bin/ssh' -R 11227:localhost:11226 -J login.remote.org n2 ... ## '/usr/bin/ssh' -R 11228:localhost:11226 -J login.remote.org n1 ... workers <- c(\"n1\", \"n2\", \"n1\") cl <- makeClusterPSOCK(   workers,   rshopts = c(\"-J\", \"login.remote.org\"),   homogeneous = FALSE,   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on Linux from MS Windows machine ## Connect to remote Unix machine 'remote.server.org' on port 2200 ## as user 'bob' from a MS Windows machine with PuTTY installed. ## Using the explicit special rshcmd = \"<putty-plink>\", will force ## makeClusterPSOCK() to search for and use the PuTTY plink software, ## preventing it from using other SSH clients on the system search PATH. ## The parallel worker is launched as: ## 'plink' -l bob -P 2200 -i C:/Users/bobby/.ssh/putty.ppk remote.server.org ... cl <- makeClusterPSOCK(   \"remote.server.org\", user = \"bob\",   rshcmd = \"<putty-plink>\",   rshopts = c(\"-P\", 2200, \"-i\", \"C:/Users/bobby/.ssh/putty.ppk\"),   dryrun = TRUE, quiet = TRUE ) #> Warning: Failed to locate a default SSH client (checked: ‘putty-plink’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.   ## EXAMPLE: Remote workers with specific setup ## Setup of remote worker with more detailed control on ## authentication and reverse SSH tunneling ## The parallel worker is launched as: ## '/usr/bin/ssh' -l johnny -v -R 11000:gateway:11942 remote.server.org ... ## \"R_DEFAULT_PACKAGES=... 'nice' '/path/to/Rscript' --no-init-file ... cl <- makeClusterPSOCK(   \"remote.server.org\", user = \"johnny\",   ## Manual configuration of reverse SSH tunneling   revtunnel = FALSE,   rshopts = c(\"-v\", \"-R 11000:gateway:11942\"),   master = \"gateway\", port = 11942,   ## Run Rscript nicely and skip any startup scripts   rscript = c(\"nice\", \"/path/to/Rscript\"),   rscript_args = c(\"--no-init-file\"),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on Linux from RStudio on MS Windows ## Connect to remote Unix machine 'remote.server.org' on port 2200 ## as user 'bob' from a MS Windows machine via RStudio's SSH client. ## Using the explicit special rshcmd = \"<rstudio-ssh>\", will force ## makeClusterPSOCK() to use the SSH client that comes with RStudio, ## preventing it from using other SSH clients on the system search PATH. ## The parallel worker is launched as: ## 'ssh' -l bob remote.server.org:2200 ... cl <- makeClusterPSOCK(   \"remote.server.org:2200\", user = \"bob\", rshcmd = \"<rstudio-ssh>\",   dryrun = TRUE, quiet = TRUE ) #> Warning: Failed to locate a default SSH client (checked: ‘rstudio-ssh’). Please specify one via argument 'rshcmd'. Will still try with ‘ssh’.   ## --------------------------------------------------------------- ## Section 3. Setting up parallel workers on HPC cluster ## --------------------------------------------------------------- ## EXAMPLE: 'Grid Engine' is a high-performance compute (HPC) job ## scheduler where one can request compute resources on multiple nodes, ## each running multiple cores. Examples of Grid Engine schedulers are ## Oracle Grid Engine (formerly Sun Grid Engine), Univa Grid Engine, ## and Son of Grid Engine - all commonly referred to as SGE schedulers. ## Each SGE cluster may have its own configuration with their own way ## of requesting parallel slots. Here are a few examples: ## ##   ## Request 18 slots on a single host ##   qsub -pe smp 18 script.sh ## ##   ## Request 18 slots on one or more hosts ##   qsub -pe mpi 18 script.sh ## ## This will launch the job script 'script.sh' on one host, while have ## reserved in total 18 slots (CPU cores) on this host and possible ## other hosts. ## ## This example shows how to use the SGE command 'qrsh' to launch ## 18 parallel workers from R, which is assumed to have been launched ## by 'script.sh'. ## ## The parallel workers are launched as: ## 'qrsh' -inherit -nostdin -V comphost01 ... ## 'qrsh' -inherit -nostdin -V comphost01 ... ## ... ## 'qrsh' -inherit -nostdin -V comphost06 ... cl <- makeClusterPSOCK(   availableWorkers(),   rshcmd = \"qrsh\", rshopts = c(\"-inherit\", \"-nostdin\", \"-V\"),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: The 'Fujitsu Technical Computing Suite' is a high-performance ## compute (HPC) job scheduler where one can request compute resources on ## multiple nodes, each running multiple cores.  For example, ## ##   pjsub -L vnode=3 -L vnode-core=18 script.sh ## ## reserves 18 cores on three nodes. The job script runs on the first ## with enviroment variables set to infer the other nodes, resulting in ## availableWorkers() to return 3 * 18 workers. When the HPC environment ## does not support SSH between compute nodes, one can use the 'pjrsh' ## command to launch the parallel workers. ## ## The parallel workers are launched as: ## 'pjrsh' comphost01 ... ## 'pjrsh' comphost01 ... ## ... ## 'pjrsh' comphost06 ... cl <- makeClusterPSOCK(   availableWorkers(),   rshcmd = \"pjrsh\",   dryrun = TRUE, quiet = TRUE )    ## --------------------------------------------------------------- ## Section 4. Setting up remote parallel workers in the cloud ## --------------------------------------------------------------- ## EXAMPLE: Remote worker running on AWS ## Launching worker on Amazon AWS EC2 running one of the ## Amazon Machine Images (AMI) provided by RStudio ## (https://www.louisaslett.com/RStudio_AMI/) ## ## The parallel worker is launched as: ## '/usr/bin/ssh' -R 11153:localhost:11153 -l ubuntu ... ## -o StrictHostKeyChecking=no -o IdentitiesOnly=yes ... ## -i ~/.ssh/my-private-aws-key.pem 1.2.3.4 ... public_ip <- \"1.2.3.4\" ssh_private_key_file <- \"~/.ssh/my-private-aws-key.pem\" cl <- makeClusterPSOCK(   ## Public IP number of EC2 instance   public_ip,   ## User name (always 'ubuntu')   user = \"ubuntu\",   ## Use private SSH key registered with AWS   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Set up .libPaths() for the 'ubuntu' user   ## and then install the future package   rscript_startup = quote(local({     p <- Sys.getenv(\"R_LIBS_USER\")     dir.create(p, recursive = TRUE, showWarnings = FALSE)     .libPaths(p)     install.packages(\"future\")   })),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Remote worker running on GCE ## Launching worker on Google Cloud Engine (GCE) running a ## container based VM (with a #cloud-config specification) public_ip <- \"1.2.3.4\" user <- \"johnny\" ssh_private_key_file <- \"~/.ssh/google_compute_engine\" cl <- makeClusterPSOCK(   ## Public IP number of GCE instance   public_ip,   ## User name (== SSH key label (sic!))   user = user,   ## Use private SSH key registered with GCE   rshopts = c(     \"-o\", \"StrictHostKeyChecking=no\",     \"-o\", \"IdentitiesOnly=yes\",     \"-i\", ssh_private_key_file   ),   ## Launch Rscript inside Docker container   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ),   dryrun = TRUE, quiet = TRUE )    ## --------------------------------------------------------------- ## Section 5. Parallel workers running locally inside virtual ## machines, Linux containers, etc. ## --------------------------------------------------------------- ## EXAMPLE: Two workers limited to 100% CPU process and 50 MiB of ## memory using Linux CGroups management. The 100% CPU quota limit ## constrain each worker to use at most one CPU worth of ## processing preventing them from overusing the machine, e.g. ## through unintended nested parallelization. The 50 MiB memory ## limit is strict - if a worker use more than this, the operating ## system will terminate the worker instantly. ## See 'man systemd.resource-control' for more details. cl <- makeClusterPSOCK(2L,   rscript = c(\"systemd-run\", \"--user\", \"--scope\",     \"-p\", \"CPUQuota=100%\",     \"-p\", \"MemoryMax=50M\", \"-p\", \"MemorySwapMax=50M\",     \"*\"   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Two workers running in Docker on the local machine ## Setup of 2 Docker workers running rocker/r-parallel ## ## The parallel workers are launched as: ## R_DEFAULT_PACKAGES=... '/usr/bin/docker' 'run' '--net=host' 'rocker/r-parallel' ... ## R_DEFAULT_PACKAGES=... '/usr/bin/docker' 'run' '--net=host' 'rocker/r-parallel' ... cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Docker container   rscript = c(     \"docker\", \"run\", \"--net=host\", \"rocker/r-parallel\",     \"Rscript\"   ),   ## IMPORTANT: Because Docker runs inside a virtual machine (VM) on macOS   ## and MS Windows (not Linux), when the R worker tries to connect back to   ## the default 'localhost' it will fail, because the main R session is   ## not running in the VM, but outside on the host.  To reach the host on   ## macOS and MS Windows, make sure to use master = \"host.docker.internal\"   master = if (.Platform$OS.type == \"unix\") NULL else \"host.docker.internal\",   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: Two workers running via Linux container 'rocker/r-parallel' from ## DockerHub on the local machine using Apptainer (formerly Singularity) ## ## The parallel workers are launched as: ## R_DEFAULT_PACKAGES=... '/usr/bin/apptainer' 'exec' 'docker://rocker/r-parallel' ... ## R_DEFAULT_PACKAGES=... '/usr/bin/apptainer' 'exec' 'docker://rocker/r-parallel' ... cl <- makeClusterPSOCK(   rep(\"localhost\", times = 2L),   ## Launch Rscript inside Linux container   rscript = c(     \"apptainer\", \"exec\", \"docker://rocker/r-parallel\",     \"Rscript\"   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: One worker running in udocker on the local machine ## Setup of a single udocker.py worker running rocker/r-parallel ## ## The parallel worker is launched as: ## R_DEFAULT_PACKAGES=... 'udocker.py' 'run' 'rocker/r-parallel' ... cl <- makeClusterPSOCK(   \"localhost\",   ## Launch Rscript inside Docker container (using udocker)   rscript = c(     \"udocker.py\", \"run\", \"rocker/r-parallel\",     \"Rscript\"   ),    ## Manually launch parallel workers   ## (need double shQuote():s because udocker.py drops one level)   rscript_args = c(     \"-e\", shQuote(shQuote(\"parallel:::.workRSOCK()\"))   ),   dryrun = TRUE, quiet = TRUE )   ## EXAMPLE: One worker running in Wine for Linux on the local machine ## To install R for MS Windows in Wine, do something like: ##   winecfg  # In GUI, set 'Windows version' to 'Windows 10' ##   wget https://cran.r-project.org/bin/windows/base/R-4.4.2-win.exe ##   wine R-4.4.2-win.exe /SILENT ## Prevent packages from being installed to R's system library: ##   chmod ugo-w \"$HOME/.wine/drive_c/Program Files/R/R-4.4.2/library/\" ## Verify it works: ##   wine \"C:/Program Files/R/R-4.4.2/bin/x64/Rscript.exe\" --version ## ## The parallel worker is launched as: ## R_DEFAULT_PACKAGES=... WINEDEBUG=fixme-all R_LIBS_SITE= R_LIBS_USER= 'wine' ... cl <- makeClusterPSOCK(1L,   rscript = c(     ## Silence Wine warnings     \"WINEDEBUG=fixme-all\",     ## Don't pass LC_* and R_LIBS* environments from host to Wine     sprintf(\"%s=\", grep(\"^(LC_|R_LIBS)\", names(Sys.getenv()), value = TRUE)),     \"wine\",     \"C:/Program Files/R/R-4.4.2/bin/x64/Rscript.exe\"   ),   dryrun = TRUE, quiet = TRUE )"},{"path":"https://parallelly.futureverse.org/reference/makeClusterSequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a ","title":"Create a ","text":"created cluster one node.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterSequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a ","text":"","code":"makeClusterSequential()"},{"path":"https://parallelly.futureverse.org/reference/makeClusterSequential.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a ","text":"Expression function calls evaluated local environment, inheriting global environment.","code":""},{"path":"https://parallelly.futureverse.org/reference/makeClusterSequential.html","id":"requirements","dir":"Reference","previous_headings":"","what":"Requirements","title":"Create a ","text":"function defined R (>= 4.4.0).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":null,"dir":"Reference","previous_headings":"","what":"Options Used by the 'parallelly' Package — parallelly.options","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables used parallelly package packages enhancing .WARNING: Note names default values options may change future versions package.  Please use care notice.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"backward-compatibility-with-the-future-package","dir":"Reference","previous_headings":"","what":"Backward compatibility with the future package","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"functions parallelly package originates future package.  widely used within future ecosystem, need keep backward compatible quite long time, order existing packages R scripts time adjust. also goes R options environment variables used configure functions. options environment variables used prefixes parallelly. R_PARALLELLY_, respectively.  backward compatibility future package, settings can also controlled options environment variables prefixes future. R_FUTURE_ notice, e.g. setting option future.availableCores.fallback=1 setting option parallelly.availableCores.fallback=1, setting environment variable R_FUTURE_AVAILABLECORES_FALLBACK=1 setting R_PARALLELLY_AVAILABLECORES_FALLBACK=1.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-number-of-parallel-workers","dir":"Reference","previous_headings":"","what":"Configuring number of parallel workers","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default results availableCores() availableWorkers(). parallelly.availableCores.logical: (logical) default value argument logical used availableCores(), availableWorkers(), availableCores() querying parallel::detectCores(logical = logical).  default TRUE just like parallel::detectCores(). parallelly.availableCores.methods: (character vector) Default lookup methods availableCores(). (Default: c(\"system\", \"cgroups.cpuset\", \"cgroups.cpuquota\", \"cgroups2.cpu.max\", \"nproc\", \"mc.cores\", \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"Bioconductor\", \"LSF\", \"PJM\", \"PBS\", \"SGE\", \"Slurm\", \"fallback\", \"custom\")) parallelly.availableCores.custom: (function) set function, function called (without arguments) availableCores() value, coerced integer, interpreted number cores. parallelly.availableCores.fallback: (integer) Number cores use core-specifying settings detected \"system\" \"nproc\".  options makes possible set default number cores returned availableCores() / availableWorkers() yet allow users schedulers override .  multi-tenant environment, HPC clusters, useful set environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK 1, set option package loaded. parallelly.availableCores.system: (integer) Number \"system\" cores used instead reported availableCores(= \"system\"). option allows effectively override parallel::detectCores() reports system . parallelly.availableCores.min: (integer) minimum number cores availableCores() allowed return. can used force multiple cores single-core environment. limit applied, names returned value appended asterisk (*).  (Default: 1L) parallelly.availableCores.omit: (integer) Number cores set aside, .e. include. parallelly.availableWorkers.methods: (character vector) Default lookup methods availableWorkers(). (Default: c(\"mc.cores\", \"BiocParallel\", \"_R_CHECK_LIMIT_CORES_\", \"Bioconductor\", \"LSF\", \"PJM\", \"PBS\", \"SGE\", \"Slurm\", \"custom\", \"cgroups.cpuset\", \"cgroups.cpuquota\", \"cgroups2.cpu.max\", \"nproc\", \"system\", \"fallback\")) parallelly.availableWorkers.custom: (function) set function, function called (without arguments) availableWorkers() value, coerced character vector, interpreted hostnames available workers.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-forked-parallel-processing","dir":"Reference","previous_headings":"","what":"Configuring forked parallel processing","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default result supportsMulticore(). parallelly.fork.enable: (logical) Enable disable forked processing.  FALSE, multicore futures becomes sequential futures.  NA, set (default), set best-practices rules decide whether supported . parallelly.supportsMulticore.disableOn: (character vector) environment R runs considered unstable forked processing. vector contains \"rstudio_console\", disabled running R RStudio Console. vector contains \"rstudio_terminal\", disabled running R RStudio Terminal. (Default: c(\"rstudio_console\", \"rstudio_terminal\")) parallelly.supportsMulticore.unstable: (character) Controls whether warning produced whenever multicore processing automatically disabled per settings option parallelly.supportsMulticore.disableOn.  \"warn\" (default), informative warning produces first time 'multicore' futures used.  \"quiet\", warning produced.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"configuring-setup-of-parallel-psock-clusters","dir":"Reference","previous_headings":"","what":"Configuring setup of parallel PSOCK clusters","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R options environment variables control default results makeClusterPSOCK() helper function makeNodePSOCK() creates individual cluster nodes. parallelly.maxWorkers.localhost: (two numerics) Maximum number localhost workers, relative availableCores(), accepted allowed. first element specifies \"soft\" limit, triggers warning, exceeded. second element specifies \"hard\" limit, triggers error exceeded. limits exist protect CPU overuse current machine, sometimes happens mistake without user causing aware. limits can disabled setting +Inf (recommended). first exist, error produced (defaults c(1.0, 3.0) corresponding maximum 100% 300% use). parallelly.makeNodePSOCK.setup_strategy: (character) \"parallel\" (default), PSOCK cluster nodes set concurrently.  \"sequential\", set sequentially. parallelly.makeNodePSOCK.validate: (logical) TRUE (default), nodes created, validated work inquiring session information, saved attribute session_info node. parallelly.makeNodePSOCK.connectTimeout: (numeric) maximum time (seconds) allowed socket connection master worker established (defaults 2*60 seconds = 2 minutes). parallelly.makeNodePSOCK.timeout: (numeric) maximum time (seconds) allowed pass without master worker communicate (defaults 302460*60 seconds = 30 days). parallelly.makeNodePSOCK.useXDR: (logical) FALSE (default), communication master workers, binary, use small-endian (faster), otherwise big-endian (\"XDR\"; slower). parallelly.makeNodePSOCK.socketOptions: (character string) set another value \"NULL\", option socketOptions set value workers startup. See base::socketConnection() details. (defaults \"-delay\") parallelly.makeNodePSOCK.rshcmd: (character vector) command run master launch process another host. parallelly.makeNodePSOCK.rshopts: (character vector) Addition command-line options appended rshcmd.  arguments applied connecting non-localhost machines. parallelly.makeNodePSOCK.tries: (integer) maximum number attempts done launch node.  used setting cluster nodes using sequential strategy. parallelly.makeNodePSOCK.tries.delay: (numeric) number seconds wait trying launch cluster node failed launch previously.  used setting cluster nodes using sequential strategy.","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"options-for-debugging","dir":"Reference","previous_headings":"","what":"Options for debugging","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"parallelly.debug: (logical) TRUE, extensive debug messages generated. (Default: FALSE)","code":""},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"environment-variables-that-set-r-options","dir":"Reference","previous_headings":"","what":"Environment variables that set R options","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"R parallelly.* options can set corresponding environment variables R_PARALLELLY_* parallelly package loaded. example, R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY=\"sequential\", option parallelly.makeNodePSOCK.setup_strategy set \"sequential\" (character). Similarly, R_PARALLELLY_AVAILABLECORES_FALLBACK=\"1\", option parallelly.availableCores.fallback set 1 (integer).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/parallelly.options.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Options Used by the 'parallelly' Package — parallelly.options","text":"","code":"# Set an R option: options(parallelly.availableCores.fallback = 1L)"},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether a process PID exists or not — pid_exists","title":"Check whether a process PID exists or not — pid_exists","text":"Check whether process PID exists ","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether a process PID exists or not — pid_exists","text":"","code":"pid_exists(pid, debug = getOption(\"parallelly.debug\", FALSE))"},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether a process PID exists or not — pid_exists","text":"pid positive integer.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether a process PID exists or not — pid_exists","text":"Returns TRUE process given PID exists, FALSE process given PID exists, NA possible check PIDs current system.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check whether a process PID exists or not — pid_exists","text":"single go-function R testing whether PID exists .  Instead, function tries identify working one among multiple possible alternatives.  method considered working PID current process successfully identified existing pid_exists(Sys.getpid()) TRUE.  working approach found, pid_exists() always return NA regardless PID tested. Unix, including macOS, alternatives tools::pskill(pid, signal = 0L) system2(\"ps\", args = pid) used. MS Windows, various alternatives system2(\"tasklist\", ...) used. Note, MS Windows machines configures allow using tasklist process IDs current one.","code":""},{"path":"https://parallelly.futureverse.org/reference/pid_exists.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Check whether a process PID exists or not — pid_exists","text":"Open Group Base Specifications Issue 7, 2018 edition, IEEE Std 1003.1-2017 (Revision IEEE Std 1003.1-2008) https://pubs.opengroup.org/onlinepubs/9699919799/functions/kill.html Microsoft, tasklist, 2021-03-03, https://learn.microsoft.com/en-us/windows-server/administration/windows-commands/tasklist R-devel thread 'Detecting whether process exists PID?', 2018-08-30. https://stat.ethz.ch/pipermail/r-devel/2018-August/076702.html","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the size of an R object when it is serialized — serializedSize","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"function goes motions serializing object, nothing bytes tally total length.","code":""},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"","code":"serializedSize(obj)"},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"obj R object.","code":""},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"(double) Number bytes needed serialize object.","code":""},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"Mike FC","code":""},{"path":"https://parallelly.futureverse.org/reference/serializedSize.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the size of an R object when it is serialized — serializedSize","text":"","code":"object.size(mtcars) #> 7208 bytes serializedSize(mtcars) #> [1] 3807"},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":null,"dir":"Reference","previous_headings":"","what":"Check If Forked Processing (","title":"Check If Forked Processing (","text":"Certain parallelization methods R rely forked processing, e.g. parallel::mclapply(), parallel::makeCluster(n, type = \"FORK\"), doMC::registerDoMC(), future::plan(\"multicore\"). Process forking done operating system support R restricted Unix-like operating systems Linux, Solaris, macOS.  R running Microsoft Windows support forked processing. R, forked processing often referred \"multicore\" processing, stems 'mc' mclapply() family functions, originally package named multicore later incorporated parallel package. function checks whether forked (aka \"multicore\") processing supported current R session.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check If Forked Processing (","text":"","code":"supportsMulticore(...)"},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check If Forked Processing (","text":"... Internal usage .","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check If Forked Processing (","text":"TRUE forked processing supported disabled, otherwise FALSE.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"support-for-process-forking","dir":"Reference","previous_headings":"","what":"Support for process forking","title":"Check If Forked Processing (","text":"R supports forked processing Unix-like operating system Linux macOS, Microsoft Windows operating system. R environments considered unstable perform parallel processing based forking. example case using RStudio, cf. RStudio Inc. recommends using forked processing running R within RStudio software. function detects running environment returns FALSE, despite underlying operating system supports forked processing. warning also produced informing user first time time function called R session. warning can disabled setting R option parallelly.supportsMulticore.unstable, environment variable R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE \"quiet\".","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"enable-or-disable-forked-processing","dir":"Reference","previous_headings":"","what":"Enable or disable forked processing","title":"Check If Forked Processing (","text":"possible disable forked processing futures setting R option parallelly.fork.enable FALSE.  Alternatively, one can set environment variable R_PARALLELLY_FORK_ENABLE false. Analogously, possible override disabled forking setting one TRUE.","code":""},{"path":"https://parallelly.futureverse.org/reference/supportsMulticore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check If Forked Processing (","text":"","code":"## Check whether or not forked processing is supported supportsMulticore() #> [1] TRUE"},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-development-version","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version (development version)","text":"Add support availableCores() availableWorkers() specify constraints = \"connections-N\", N specifies number connections leave free launching PSOCK cluster number cores. Add .equal() connection, can distinguish two connections share connection index, connection, e.g. one created, closed, another one kind created.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-development-version","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version (development version)","text":"availableCores() respect method = \"fallback\" since v1.41.0 system value method = \"/proc/self/status\".","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1430","dir":"Changelog","previous_headings":"","what":"Version 1.43.0","title":"Version 1.43.0","text":"CRAN release: 2025-03-24","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-43-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.43.0","text":"Now availableCores() memoizes values components. means soon called, environment variables NSLOTS longer queried. Starting R 4.5.0, one can use parallel::makeCluster(n, type =    parallelly::RPSOCK) alternative parallelly::makeClusterPSOCK(n). Similarly, type =    parallelly::RMPI creates cluster using parallelly::makeClusterMPI(), type = parallelly::SEQ creates cluster using parallelly::makeClusterSequential(). first introduced parallelly 1.38.0, rename PSOCK RPSOCK MPI RMPI minimize risk mistaking built-types parallel package. R stands “Rich”.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-43-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.43.0","text":"Add help R option parallelly.maxWorkers.localhost limits. Improved warning error messages produced settings exceeded.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-43-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"Version 1.43.0","text":"R option future.debug longer used fallback option parallelly.debug.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-43-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.43.0","text":"isNodeAlive() produce warnings doTryCatch(return(expr),    name, parentenv, handler) : NAs introduced coercion MS Windows. Improved internal tasklist parses used test whether process alive. availableCores() produce Error: Error    cache_controller[[field]] : subscript bounds ... getCGroups1CpuQuota -> getCGroups1CpuPeriodMicroseconds.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1420","dir":"Changelog","previous_headings":"","what":"Version 1.42.0","title":"Version 1.42.0","text":"CRAN release: 2025-01-30","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-42-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.42.0","text":"Now availableCores() availableWorkers() support also CGroups v1 CGroups v2 enabled machine. Previously, configurations completely ignored.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-42-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.42.0","text":"Call isNodeAlive() killNode() cluster nodes running external machines produce Error match.arg(type, choices =    known_types, several.ok = FALSE) : 'arg' must length 1. bug introduced version 1.38.0 (2024-07-27), adding richer support rscript_sh argument. Call isNodeAlive() killNode() cluster nodes running external machines produce Error: ‘length(rsh_call) == 1L’    TRUE option rshopts specified creation. value availableCores() numeric rather integer documented. harmless bug introduced version 1.31.0 (2022-04-07).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1410","dir":"Changelog","previous_headings":"","what":"Version 1.41.0","title":"Version 1.41.0","text":"CRAN release: 2024-12-18","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-41-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.41.0","text":"Now availableCores() queries also /proc/self/status CPU affinity allotments. makeClusterPSOCK() now produce error, rather warning, local system command used launch parallel worker failed non-zero exit code. Now serializedSize() always returns double. Previously, return integer, value represented integer. However, turned returning integer increased risk integer overflow later , say, two values added together.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-41-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.41.0","text":"makeClusterPSOCK() MS Windows failed launch remote workers, warnings \"system(local_cmd, wait = FALSE, input =    input) : 'C:\\WINDOWS\\System32\\OpenSSH\\ssh.exe' found\". bug introduced version 1.38.0 (2024-07-27), adding richer support rscript_sh argument.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1401","dir":"Changelog","previous_headings":"","what":"Version 1.40.1","title":"Version 1.40.1","text":"CRAN release: 2024-12-04","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-40-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.40.1","text":"internal vignette engine wrote files user’s home directory. due brief debugging vignette engine forgotten .","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1400","dir":"Changelog","previous_headings":"","what":"Version 1.40.0","title":"Version 1.40.0","text":"CRAN release: 2024-12-03","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-40-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.40.0","text":"Argument user makeClusterPSOCK() may now vector usernames - one worker specified.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-40-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.40.0","text":"Add vignettes setup cluster parallel workers local machine, external machines, cloud, HPC environments, .","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-40-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.40.0","text":"Querying cgroups v1 ‘cpuquota’ CPU limits broke previous release (v1.39.0). availableCores() produce error Failed identify mount    point CGroups v1 controller 'cpuset' systems. availableWorkers() produce invalid warning Identified 8    workers ‘PE_HOSTFILE’ file (...),    environment variable ‘NSLOTS’ = 8 running via Grid Engine job scheduler.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1390","dir":"Changelog","previous_headings":"","what":"Version 1.39.0","title":"Version 1.39.0","text":"CRAN release: 2024-11-07","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-39-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.39.0","text":"Environment variables R_PARALLELLY_RANDOM_PORTS now supports multiple, comma-separated port specifications, e.g. \"20001:20999\" \"1068:1099,20001:20999,40530\".","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-39-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.39.0","text":"Add example help(\"makeClusterPSOCK\") use systemd-run limit workers’ CPU quota memory allowances.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-39-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"Version 1.39.0","text":"Improved cgroups v1 v2 settings queried.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-39-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.39.0","text":"Now availableCores() better job detecting cgroups v2 cpu.max CPU restrictions.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1380","dir":"Changelog","previous_headings":"","what":"Version 1.38.0","title":"Version 1.38.0","text":"CRAN release: 2024-07-27","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-38-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.38.0","text":"Now argument rshcmd makeNodePSOCK() can function. must accept least two arguments named rshopts worker. rshopts argument character vector length zero . worker argument string hostname. function must return single string. Now makeNodePSOCK() accepts rscript_sh = \"none\", skips quoting Rscript call. Now makeNodePSOCK() accepts rscript_sh length one two. length(rscript_sh) == 2, rscript_sh[1] inner rscript_sh[2] outer shell quoting Rscript call. precisely, rscript_sh[1] Rscript arguments need shell quoting (e.g. Rscript -e \"<expr>\"), rscript_sh[2] whole Rscript ... call. Add makeClusterSequential() available R (>= 4.4.0). Starting R 4.5.0 (currently R-devel), one can use parallel::makeCluster(n, type = parallelly::PSOCK) alternative parallelly::makeClusterPSOCK(n). Similarly, type    = parallelly::MPI creates cluster using parallelly::makeClusterMPI(), type = parallelly::SEQ creates cluster using parallelly::makeClusterSequential(). Add serializedSize() calculating size object counting number bytes required serialize .","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-38-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.38.0","text":"Environment variable R_PARALLELLY_MAXWORKERS_LOCALHOST interpreted integers rather doubles.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1371","dir":"Changelog","previous_headings":"","what":"Version 1.37.1","title":"Version 1.37.1","text":"CRAN release: 2024-02-29","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-37-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.37.1","text":"Version 1.37.0 install FreeBSD.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1370","dir":"Changelog","previous_headings":"","what":"Version 1.37.0","title":"Version 1.37.0","text":"CRAN release: 2024-02-14","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-37-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.37.0","text":"makeClusterPSOCK(nworkers) gained protection setting many localhost workers relative number available CPU cores. nworkers / availableCores() greater 1.0 (100%), warning produced. greater 3.0 (300%), error produced. limits can configured R option parallelly.maxWorkers.localhost. checks skipped nworkers inherits AsIs, e.g. makeClusterPSOCK((16)). current 3.0 (300%) limit likely decreased future release. packages fail R CMD check ---cran validation enabled. example, one package uses 8 parallel workers examples, R CMD check ---cran allows two. give packages time fixed, CRAN-enforced limits ignored now.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-37-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"Version 1.37.0","text":"makeClusterPSOCK() produce confusing error Invalid port:    NA non-available port requested. Now error message informative, e.g. Argument 'port' specifies non-available port(s): 80.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-37-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.37.0","text":"internal method checking TCP port available improved. Previously, incorrectly conclude port available, .","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1360","dir":"Changelog","previous_headings":"","what":"Version 1.36.0","title":"Version 1.36.0","text":"CRAN release: 2023-05-26","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-36-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.36.0","text":"isNodeAlive() killNode() now support also worker processes run remote machines. connecting remote machine using method used launch worker, typically SSH, R calls way. isNodeAlive() killNode() gained argument timeout controlling maximum time, seconds, giving returning NA. Add cloneNode(), can used “restart” RichSOCKnode cluster nodes. Argument worker makeNodePSOCK() now takes optional, logical attribute localhost manually specify worker localhost worker. Add print() RichSOCKnode, gives details print() SOCKnode. print() RichSOCKnode RichSOCKcluster report nodes broken connections. Add .cluster() RichSOCKnode, returns RichSOCKcluster. Introduce R option parallelly.supportsMulticore.disableOn control multicore processing disabled default.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-36-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.36.0","text":"Calling killNode() RichSOCKnode node theoretically kill process current machine process ID (PID), although parallel worker (node) running another machine. isNodeAlive() RichSOCKnode node theoretically return TRUE process process ID (PID) current machine, although parallel worker (node) running another machine. isLocalHost() SOCK0node declared S3 method.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1350","dir":"Changelog","previous_headings":"","what":"Version 1.35.0","title":"Version 1.35.0","text":"CRAN release: 2023-03-22","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-35-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.35.0","text":"Now freePort() defaults default = NA_integer_, NA_integer_ returned free port found. However, R (< 4.0.0), support port querying, use default = \"random\".","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-35-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.35.0","text":"Mention help(\"makeClusterPSOCK\") rscript_sh = \"cmd\" needed remote machines run MS Windows.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-35-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.35.0","text":"makeClusterPSOCK(..., verbose = TRUE) show verbose output. One still set option parallelly.debug TRUE. availableWorkers() produce false sanity-check warnings mismatching ‘PE_HOSTFILE’ content ‘NSLOTS’ certain SGE-cluster configurations.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1340","dir":"Changelog","previous_headings":"","what":"Version 1.34.0","title":"Version 1.34.0","text":"CRAN release: 2023-01-13","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-34-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.34.0","text":"Add support availableWorkers(constraints = \"connections\"), limits number workers can used current number free R connections according freeConnections(). maximum number PSOCK, SOCK, MPI parallel cluster nodes can open without running available R connections.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-34-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.34.0","text":"availableCores() produce warning .na(constraints) :    .na() applied non-(list vector) type 'NULL' running R (< 4.0.0). availableWorkers() acknowledge \"cgroups2.cpu.max\" \"Bioconductor\" methods added availableCores() parallelly 1.33.0 (2022-12-13). also acknowledge methods \"cgroups.cpuset\" \"cgroups.cpuquota\" added parallelly 1.31.0 (2022-04-07), \"nproc\" added parallelly 1.26.1 (2021-06-29). makeClusterPSOCK() failed connect parallel workers within connectTimeout time limit, either produce Error    sprintf(ngettext(failed, \"Cluster setup failed    (connectTimeout=%.1f seconds). %d worker %d failed    connect.\", : invalid format '%d'; use format %f, %e, %g %   numeric objects instead informative error message, error message incorrect information.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1330","dir":"Changelog","previous_headings":"","what":"Version 1.33.0","title":"Version 1.33.0","text":"CRAN release: 2022-12-14","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-33-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.33.0","text":"Add killNode() terminate cluster nodes via process signaling. Currently, supported parallel workers local machine, created makeClusterPSOCK(). makeClusterPSOCK() likes now assert running R session enough permissions operating system system calls system2(\"Rscript --version\"). , informative error message produced. Unix, availableCores() queries also control groups v2 (cgroups v2) field cpu.max possible CPU quota allocation. CPU quota set, number CPUs rounded nearest integer, unless less 0.5, case ’s rounded single CPU. example, cgroups CPU quotas can set limit total CPU load, Linux containers, e.g. docker    run --cpus=3.5 .... Add support availableCores(methods = \"connections\"), returns current number free R connections per freeConnections(). maximum number PSOCK, SOCK, MPI parallel cluster nodes can open without running available R connections. convenient way use methods availableCores(constraints = \"connections\"). Now availableCores() recognizes environment variable IS_BIOC_BUILD_MACHINE, set true Bioconductor (>= 3.16) check servers. true, maximum four (4) cores returned. new environment variable replaces legacy variable BBS_HOME used Bioconductor (<= 3.15). availableCores() splits method \"BiocParallel\" two; \"BiocParallel\" \"Bioconductor\". former queries environment variable BIOCPARALLEL_WORKER_NUMBER latter IS_BIOC_BUILD_MACHINE. means availableCores(=    \"\") now reports . isNodeAlive() now produce -per-session informative warning detects possible check whether another process alive current machine.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-33-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.33.0","text":"Add section help(\"makeClusterPSOCK\", package = \"parallelly\") explaining R CMD check may produce “checking detritus temp directory … NOTE” avoid . Add section ‘package developers’ help(\"makeClusterPSOCK\",    package = \"parallelly\") reminding us need stop clusters created package examples, tests, vignettes.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-33-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.33.0","text":"isNodeAlive() failed record method works testing process exists , meant keep trying methods time. Similarly, none works, still keep trying time instead returning NA immediately. systems, failing check whether process exists result one warnings, case warnings produced call isNodeAlive().","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1321","dir":"Changelog","previous_headings":"","what":"Version 1.32.1","title":"Version 1.32.1","text":"CRAN release: 2022-07-21","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-32-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.32.1","text":"host element SOCK0node SOCKnode objects created makeClusterPSOCK() lost attribute localhost localhost workers. made error messages future package less informative.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1320","dir":"Changelog","previous_headings":"","what":"Version 1.32.0","title":"Version 1.32.0","text":"CRAN release: 2022-06-07","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-32-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.32.0","text":"default argument revtunnel makeNodePSOCK(), therefore also makeClusterPSOCK(), now NA, means ’s agile whether rshcmd[1] specifies SSH client, . SSH used, resolve revtunnel = TRUE, otherwise revtunnel = FALSE. removed need setting revtunnel = FALSE, non-SSH clients used.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-32-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.32.0","text":"availableCores() availableWorkers() gained support ‘Fujitsu Technical Computing Suite’ job scheduler. Specifically, acknowledges environment variables PJM_VNODE_CORE, PJM_PROC_BY_NODE, PJM_O_NODEINF. See help(\"makeClusterPSOCK\", package = \"parallelly\") example.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-32-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.32.0","text":"makeClusterPSOCK() fail Error:    node$session_info$process$pid == pid TRUE running R Simplified Chinese (LANGUAGE=zh_CN), Traditional Chinese (Taiwan) (LANGUAGE=zh_TW), Korean (LANGUAGE=ko) locales. warnings errors showed wrong call.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1311","dir":"Changelog","previous_headings":"","what":"Version 1.31.1","title":"Version 1.31.1","text":"CRAN release: 2022-04-22","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-31-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.31.1","text":"Changes option parallelly.availableCores.system ignored done first call availableCores(). availableCores() option parallelly.availableCores.system set less parallel::detectCores() produce warning, e.g. “[INTERNAL]: ignore cgroups CPU set, contains one CPU indices range [0,0]: 0-7”.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1310","dir":"Changelog","previous_headings":"","what":"Version 1.31.0","title":"Version 1.31.0","text":"CRAN release: 2022-04-07","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-31-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.31.0","text":"Changed default argument default freePort() \"random\", used \"first\". main reason make sure default behavior return random port also R (< 4.0.0) test whether port available.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-31-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.31.0","text":"Unix, availableCores() now queries also control groups (cgroups) fields cpu.cfs_quota_us cpu.cfs_period_us, possible CPU quota allocation. CPU quota set, number CPUs rounded nearest integer, unless less 0.5, case ’s rounded single CPU. example, cgroups CPU quotas can set limit total CPU load, Linux containers, e.g. docker run --cpus=3.5 .... addition cgroups CPU quotas, availableCores() also queries cgroups possible CPU affinity, available field cpuset.set. give result already existing ‘nproc’ method gives. However, systems nproc tool installed, case new approach work. high-performance compute (HPC) environments set CPU affinity jobs overuse CPUs. may also set Linux containers, e.g. docker run --cpuset-cpus=0-2,8 .... minimum value returned availableCores() one (1). can overridden new option parallelly.availableCores.min. can used test parallelization methods single-core machines, e.g. options(parallelly.availableCores.min = 2L).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-31-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.31.0","text":"‘nproc’ result availableCores() ignored nproc > 9. availableCores() return ‘fallback’ value ‘system’ ‘nproc’ information available. However, case, want return ‘nproc’ ‘nproc’ != ‘system’, strong indication number CPU cores limited control groups (cgroups) Linux. ‘nproc’ == ‘system’, tell whether cgroups enabled , means fall back ‘fallback’ value evidence another number cores available current R process. Technically, canPortBeUsed() falsely return FALSE port check interrupted , say, user interrupt. freePort(ports, default = \"random\") always use return ports[1] system allow testing port available , none specified ports available.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1300","dir":"Changelog","previous_headings":"","what":"Version 1.30.0","title":"Version 1.30.0","text":"CRAN release: 2021-12-17","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-30-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.30.0","text":"makeNodePSOCK(), therefore also makeClusterPSOCK(), gained argument rscript_sh, controls Rscript arguments shell quoted. default make best guess type shell used cluster node launched. launched locally, whatever platform current R session running, .e. either POSIX shell (\"sh\") MS Windows (\"cmd\"). remotely, assumption POSIX shell (\"sh\") used. makeNodePSOCK(), therefore also makeClusterPSOCK(), gained argument default_packages, controls default set R packages attached cluster node startup. Moreover, argument rscript specifies ‘Rscript’ executable, argument default_packages used populate Rscript command-line option --default-packages=.... rscript specifies something else, e.g. ‘R’ ‘Rterm’ executable, environment variable R_DEFAULT_PACKAGES=... set accordingly launching cluster node. Argument rscript_args makeClusterPSOCK() now supports \"*\" values. used, corresponding element replaced internally added Rscript command-line options. specified, options appended end.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-30-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.30.0","text":"makeClusterPSOCK() support backslashes (\\) rscript_libs, backslashes may originate , example, Windows network drives. result worker silently ignore rscript_libs components backslashes. package detects R CMD check runs adjust default settings via environment variables order play nicer machine checks running. environment variables case ignored since parallelly 1.26.0.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1290","dir":"Changelog","previous_headings":"","what":"Version 1.29.0","title":"Version 1.29.0","text":"CRAN release: 2021-11-21","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-29-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.29.0","text":"makeClusterPSOCK() launches parallel workers option socketOptions set \"-delay\" default. decreases communication latency workers main R session, significantly Unix. option requires R (>= 4.1.0) effect early versions R.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-29-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.29.0","text":"Added argument socketOptions makeClusterPSOCK(), sets corresponding R option cluster node launched. Argument rscript_envs makeClusterPSOCK() can also used unset environment variables cluster nodes. named element value NA_character_ unset. Argument rscript makeClusterPSOCK() now supports \"*\" values. used, corresponding element replaced \"Rscript\", homogenous = TRUE, absolute path current ‘Rscript’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-29-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.29.0","text":"Add makeClusterPSOCK() example launch workers distributed across multiple CPU Groups MS Windows 10.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-29-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.29.0","text":"isForkedChild() return TRUE forked child process, , already called parent R process. Using argument rscript_startup cause makeClusterPSOCK() fail R-devel (>= r80666).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1281","dir":"Changelog","previous_headings":"","what":"Version 1.28.1","title":"Version 1.28.1","text":"CRAN release: 2021-09-09","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"cran-policies-1-28-1","dir":"Changelog","previous_headings":"","what":"CRAN Policies","title":"Version 1.28.1","text":"elapsed run times MS Windows.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-28-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.28.0","text":"Add isNodeAlive() check whether cluster cluster nodes alive . Add isForkedChild() check whether current R process forked child process.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-28-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.28.0","text":"Environment variable R_PARALLELLY_SUPPORTSMULTICORE_UNSTABLE incorrectly parsed logical instead character string. variables set , say, \"quiet\", cause error package loaded. makeClusterPSOCK() failed fall back setup_strategy =    \"sequential\", supported current R version.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1270","dir":"Changelog","previous_headings":"","what":"Version 1.27.0","title":"Version 1.27.0","text":"CRAN release: 2021-07-19","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-27-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.27.0","text":"availableCores() availableWorkers() now respects environment variable BIOCPARALLEL_WORKER_NUMBER introduced BiocParallel (>= 1.27.2). also respect BBS_HOME set Bioconductor check servers limit number parallel workers checking Bioconductor packages.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"workaround-1-27-0","dir":"Changelog","previous_headings":"","what":"Workaround","title":"Version 1.27.0","text":"makeClusterPSOCK() parallel::makeCluster() failed error “Cluster setup failed.   workers failed connect.” using new default setup_strategy = \"parallel\" tcltk package loaded running R (>= 4.0.0 && <= 4.1.0) macOS. Now parallelly forces setup_strategy =    \"sequential\" tcltk package loaded R versions.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-27-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.27.0","text":"makeClusterPSOCK(..., setup_strategy = \"parallel\") forget close socket connection used set workers. socket connection closed garbage collector eventually warning. parallelly::makeClusterPSOCK() fail “Error freePort(port) : Unknown value argument ‘port’: ‘auto’” environment variable R_PARALLEL_PORT set port number. parallelly::availableCores() produce ‘Error (grepl(“^ [1-9]$”, res)) return(.integer(res)) : argument length zero’ Linux systems without nproc installed.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1261","dir":"Changelog","previous_headings":"","what":"Version 1.26.1","title":"Version 1.26.1","text":"CRAN release: 2021-06-30","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-26-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.26.1","text":"print() RichSOCKcluster mentions cluster registered automatically stopped garbage collector.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"workaround-1-26-1","dir":"Changelog","previous_headings":"","what":"Workaround","title":"Version 1.26.1","text":"Depending R version used, RStudio Console support new setup_strategy = \"parallel\" using makeClusterPSOCK() parallel::makeCluster(). symptom , long wait, result “Error makeClusterPSOCK(workers, …) : Cluster setup failed.   workers failed connect.” due bug R, fixed R (>= 4.1.1) also recent R 4.1.0 Patched. R (>= 4.0.0) R (<= 4.1.0), release works around problem forcing setup_strategy = \"sequential parallelly parallel running RStudio Console. wish override behavior, can always set option parallelly.makeNodePSOCK.setup_strategy \"parallel\", e.g. ~/.Rprofile file. Alternatively, can set environment variable R_PARALLELLY_MAKENODEPSOCK_SETUP_STRATEGY=parallel, e.g. ~/.Renviron file.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-26-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.26.1","text":"systems nproc installed, availableCores() limited environment variables OMP_NUM_THREADS OMP_THREAD_LIMIT, set. example, conservative systems set OMP_NUM_THREADS=1 default, availableCores() pick via nproc return 1. intended behavior. Now environment variables temporarily unset querying nproc.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1260","dir":"Changelog","previous_headings":"","what":"Version 1.26.0","title":"Version 1.26.0","text":"CRAN release: 2021-06-09","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-26-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.26.0","text":"R_PARALLELLY_* (R_FUTURE_*) environment variables now read parallelly package loaded, set corresponding parallelly.* option. Previously, environment variables queried different functions fallback option set. parsing package loaded, decrease overhead functions, clarifies options can changed runtime whereas environment variables set startup.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-26-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.26.0","text":"makeClusterPSOCK() now support setting cluster nodes parallel similarly parallel::makePSOCKcluster() . significantly reduces setup turnaround time. supported R (>= 4.0.0). revert sequential setup strategy, set R option parallelly.makeNodePSOCK.setup_strategy \"sequential\". Add freePort() get random TCP port can opened.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-26-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.26.0","text":"Documenting R options environment variables used package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-26-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.26.0","text":"R option parallelly.availableCores.fallback environment variable R_PARALLELLY_AVAILABLECORES_FALLBACK ignored since parallelly 1.22.0, support ‘nproc’ added availableCores().","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1250","dir":"Changelog","previous_headings":"","what":"Version 1.25.0","title":"Version 1.25.0","text":"CRAN release: 2021-04-30","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-25-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.25.0","text":"default SSH client MS Windows 10 now built ssh client. means regardless whether Linux, macOS, Windows 10, setting parallel workers external machines SSH finally works box without install PuTTY SSH clients. possible workaround found Windows 10 bug preventing us using reverse tunneling SSH. turns bug reveals using hostname ‘localhost’ ‘127.0.0.1’, use latter.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-25-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.25.0","text":"availableCores() gained argument omit make easier put aside zero cores used parallel processing. example, system four cores, availableCores(omit =    1) returns 3. Importantly, since availableCores() guaranteed always return positive integer, availableCores(omit = 4) ==    1, even systems four fewer cores. Using availableCores() - 4 systems return non-positive value, give error downstream.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-25-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.25.0","text":"makeClusterPSOCK(), actually makeNodePSOCK(), accept types environment variable names using rscript_envs, e.g. give error tried pass _R_CLASS_MATRIX_ARRAY_. makeClusterPSOCK() “length > 1 coercion logical” bug affect especially MS Windows 10 users.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1240","dir":"Changelog","previous_headings":"","what":"Version 1.24.0","title":"Version 1.24.0","text":"CRAN release: 2021-03-14","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-24-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.24.0","text":"default SSH client MS Windows now, order availability: () plink PuTTY software, (ii) ssh RStudio distribution, (iii) ssh Windows 10. Previously, latter considered first still bug preventing us using reverse tunneling.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-24-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.24.0","text":"makeClusterPSOCK(), actually makeNodePSOCK(), gained argument quiet, can used silence output produced manual = TRUE. c() cluster objects now warns duplicated cluster nodes. Add isForkedNode() test cluster node runs forked process. Add isLocalhostNode() test cluster node runs current machine. Now availableCores() availableWorkers() avoid recursive calls custom function given options parallelly.availableCores.custom parallelly.availableWorkers.custom, respectively. availableWorkers() now recognizes Slurm environment variable SLURM_JOB_NODELIST, e.g. \"dev1,n[3-4,095-120]\". use scontrol show hostnames \"$SLURM_JOB_NODELIST\" expand , supported current machine, otherwise attempt parse expand nodelist specification using R. either environment variable SLURM_JOB_CPUS_PER_NODE SLURM_TASKS_PER_NODE set, node nodelist represented number times. addition, environment variable SLURM_CPUS_PER_TASK (always scalar), also respected.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-24-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"Version 1.24.0","text":"code now using parallelly. prefix options R_PARALLELLY_ prefix environment variables. Settings use corresponding future. R_FUTURE_ prefixes still recognized.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-24-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.24.0","text":"availableCores() respect environment variable SLURM_TASKS_PER_NODE job allocated one node. argument quiet introduced future 1.19.1 mistakenly dropped parallelly 1.20.0 released, therefore also future (>= 1.20.0).","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1230","dir":"Changelog","previous_headings":"","what":"Version 1.23.0","title":"Version 1.23.0","text":"CRAN release: 2021-01-04","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-23-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.23.0","text":"availableCores(), availableWorkers(), freeCores() gained argument logical, passed parallel::detectCores() -. default TRUE can changed setting R option parallelly.availableCores.logical. option can turn set via environment variable R_PARALLELLY_AVAILABLECORES_LOGICAL applied () package loaded. Now makeClusterPSOCK() asserts enough free connections available attempting create parallel workers. many workers requested, informative error message produced. Add availableConnections() freeConnections() infer maximum number connections current R installation can open time many currently free used. limit typically 128 may different custom R installations built source.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1220","dir":"Changelog","previous_headings":"","what":"Version 1.22.0","title":"Version 1.22.0","text":"CRAN release: 2020-12-13","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-22-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.22.0","text":"Now availableCores() queries also Unix command nproc, available. make respect number CPU/cores limited ‘cgroups’ Linux containers. PSOCK cluster workers now set communicate using little endian (useXDR = FALSE) instead big endian (useXDR = TRUE). Since modern systems use little endian, useXDR = FALSE speeds communication noticeably (10-15%) systems. default value argument can controlled R option parallelly.makeNodePSOCK.useXDR corresponding environment variable R_PARALLELLY_MAKENODEPSOCK_USEXDR.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"beta-features-1-22-0","dir":"Changelog","previous_headings":"","what":"Beta Features","title":"Version 1.22.0","text":"Add cpuLoad() querying “average” system load Unix-like systems. Add freeCores() estimating average number unused cores based average system load given cpuLoad().","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-22-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.22.0","text":"Except environment variables R_FUTURE_AVAILABLECORES_FALLBACK R_FUTURE_AVAILABLECORES_SYSTEM, none R_PARALLELLY_* R_FUTURE_* ones recognized.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1210","dir":"Changelog","previous_headings":"","what":"Version 1.21.0","title":"Version 1.21.0","text":"CRAN release: 2020-10-27","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-21-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.21.0","text":"Removed find_rshcmd() never meant exported.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-21-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.21.0","text":"makeClusterPSOCK() gained argument validate control whether nodes tested ’ve created. validation done querying node session information, saved attribute session_info cluster node object. information also used error messages, available. validation done since version 1.5.0 now can disabled. default argument validate can controlled via R options environment variable. Now makeNodePSOCK(..., rscript_envs = \"UNKNOWN\") produces informative warning non-existing environment variables skipped.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-21-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.21.0","text":"makeClusterPSOCK() produce error ‘one node produced error: find function “getOptionOrEnvVar”’ parallelly available node. makeClusterPSOCK() attempt load parallelly worker. ’s available worker, result silent warning worker. Now parallelly loaded. makeClusterPSOCK(..., tries = n) retry setup cluster node also errors unrelated node setup node connection errors. error message using invalid rscript_envs argument makeClusterPSOCK() reported value rscript_libs (sic!). makeNodePSOCK(..., rscript_envs = \"UNKNOWN\") result error trying launch cluster node.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"deprecated-and-defunct-1-21-0","dir":"Changelog","previous_headings":"","what":"Deprecated and Defunct","title":"Version 1.21.0","text":"Removed find_rshcmd() never meant exported.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"version-1200","dir":"Changelog","previous_headings":"","what":"Version 1.20.0","title":"Version 1.20.0","text":"CRAN release: 2020-10-20","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-20-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.20.0","text":"Add availableCores(), availableWorkers(), supportsMulticore(), .cluster(), autoStopCluster(), makeClusterMPI(), makeClusterPSOCK(), makeNodePSOCK() future package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-20-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.20.0","text":"Add isConnectionValid() connectionId() adopted internal code future package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-20-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.20.0","text":"Renamed environment variable R_FUTURE_MAKENODEPSOCK_tries used makeClusterPSOCK() R_FUTURE_MAKENODEPSOCK_TRIES. connectionId() return -1L Solaris connections internal ‘nil’ pointers reported ‘0’ - ‘nil’ ‘0x0’.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"history-1-20-0","dir":"Changelog","previous_headings":"","what":"History","title":"Version 1.20.0","text":"excerpt future’s NEWS entries related functions package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"significant-changes-1-19-0","dir":"Changelog","previous_headings":"","what":"Significant Changes","title":"Version 1.19.0","text":"Now availableCores() better supports Slurm. Specifically, environment variable SLURM_CPUS_PER_TASK set, requires option --slurm-cpus-per-task=n specified SLURM_JOB_NUM_NODES=1, falls back using SLURM_CPUS_ON_NODE, e.g. using --ntasks=n. Now availableCores() availableWorkers() supports LSF/OpenLava. Specifically, acknowledge environment variable LSB_DJOB_NUMPROC LSB_HOSTS, respectively.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-19-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.19.0","text":"makeClusterPSOCK() now retry create cluster node tries (default: 3) times giving . argument port species one port (e.g. port = \"random\") also attempt find valid random port tries times giving . pre-validation random port supported R (>= 4.0.0) skipped otherwise. makeClusterPSOCK() skips shell quoting elements rscript inherits AsIs. makeClusterPSOCK(), actually makeNodePSOCK(), gained argument quiet, can used silence output produced manual = TRUE.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"performance-1-19-0","dir":"Changelog","previous_headings":"","what":"Performance","title":"Version 1.19.0","text":"Now plan(multisession), plan(cluster, workers = <number>), makeClusterPSOCK() use internally, sets localhost workers twice fast compared versions since future 1.12.0, brings back par bare-bone parallel::makeCluster(..., setup_strategy = \"sequential\") setup. slowdown introduced future 1.12.0 (2019-03-07) protection leaving stray R processes behind failed worker startup implemented. protection now makes use memoization speedup.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-18-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.18.0","text":"print() RichSOCKcluster gives information name host also version R platform node (“worker”), e.g. “Socket cluster 3 nodes 2 nodes host ‘localhost’ (R version 4.0.0 (2020-04-24), platform x86_64-w64-mingw32), 1 node host ‘n3’ (R version 3.6.3 (2020-02-29), platform x86_64-pc-linux-gnu)”. now possible set environment variables workers launched makeClusterPSOCK() specify <name>=<value> part rscript vector argument, e.g. rscript=c(\"ABC=123\", \"DEF='hello world'\", \"Rscript\"). works elements rscript match regular expression \"^ [[:alpha:]_][[:alnum:]_]*=.*\" longer shell quoted. makeClusterPSOCK() now returns cluster addition inheriting SOCKcluster also inherit RichSOCKcluster.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-18-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.18.0","text":"Made makeClusterPSOCK() makeNodePSOCK() agile name change parallel:::.slaveRSOCK() parallel:::.workRSOCK() R (>= 4.1.0). makeClusterPSOCK(..., rscript) try locate rscript[1] argument homogeneous FALSE (inferred FALSE). makeClusterPSOCK(..., rscript_envs) result syntax error starting workers due non-ASCII quotation marks option useFancyQuotes set FALSE.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-17-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.17.0","text":"makeClusterPSOCK() gained argument rscript_envs setting environment variables workers startup, e.g. rscript_envs =    c(FOO = \"3.14\", \"BAR\").","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"miscellaneous-1-17-0","dir":"Changelog","previous_headings":"","what":"Miscellaneous","title":"Version 1.17.0","text":"CRAN servers _R_CHECK_LIMIT_CORES_ set. better emulate CRAN submission checks, future package , loaded, set environment variable TRUE unset R    CMD check running. Note future::availableCores() respects _R_CHECK_LIMIT_CORES_ returns 2L (two cores) detected.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-15-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.15.1","text":"default range ports makeClusterPSOCK() draws random port (argument port specified) can now controlled environment variable R_FUTURE_RANDOM_PORTS. default range still 11000:11999 parallel package.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-15-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.15.0","text":"Added ‘Troubleshooting’ section ?makeClusterPSOCK instructions troubleshoot setup local remote clusters fail.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-15-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.15.0","text":"makeClusterPSOCK() produce warnings like “open file ‘/tmp/alice/Rtmpi69yYF/future.parent=2622.a3e32bc6af7.pid’: file”, e.g. launching R workers running Docker containers. makeClusterMPI() work MPI clusters ‘comm’ ‘1’.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-13-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.13.0","text":"Now availableCores() also recognizes PBS environment variable NCPUS, PBSPro scheduler set PBS_NUM_PPN. , option future.availableCores.custom set function, availableCores() call function interpret value number cores. Analogously, option future.availableWorkers.custom can used specify hostnames set workers availableWorkers() sees. new options provide mechanism anyone customize availableCores() availableWorkers() case (yet) recognize, say, environment variables specific user’s compute environment HPC scheduler. makeClusterPSOCK() gained support argument rscript_startup evaluating one R expressions background R worker prior worker event loop launching. provides convenient approach use, say, rscript_args =    c(\"-e\", sQuote(code)). makeClusterPSOCK() gained support argument rscript_libs control R package library search path workers. example, prepend folder ~/R-libs workers, use rscript_libs = c(\"~/R-libs\", \"*\"), \"*\" resolved current .libPaths() workers.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-13-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.13.0","text":"makeClusterPSOCK() shell quote Rscript executable running pre-tests checking whether localhost Rscript processes can killed PIDs .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-12-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.12.0","text":"makeClusterPSOCK() fails create one many nodes, attempt stop nodes successfully created. lowers risk leaving R worker processes behind.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-12-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.12.0","text":"makeClusterPSOCK() future (>= 1.11.1) produced warnings argument rscript length(rscript) > 1.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-1-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.11.1.1","text":"makeClusterPSOCK() fails connect worker, produces error detailed information happened. rare cases, another error produced generating information workers PID .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-11-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.11.1","text":"defaults several arguments makeClusterPSOCK() makeNodePSOCK() can now controlled via environment variables addition R options supported past. advantage using environment variables inherited child processes, also nested ones.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"software-quality-1-11-1","dir":"Changelog","previous_headings":"","what":"Software Quality","title":"Version 1.11.1","text":"TESTS: future package loaded, checks whether R    CMD check running . , future-specific environment variables adjusted tests play nice testing environment. instance, sets socket connection timeout PSOCK cluster workers 120 seconds (instead default 30 days!). lower risk zombie worker processes cluttering test machine (e.g. CRAN servers) case worker process left behind despite main R processes terminated. Note adjustments applied automatically checks package depends , imports, future package.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.11.1","text":"Whenever makeClusterPSOCK() fail connect worker, instance due port clash, leave R worker process running - also main R process terminated. worker running machine, makeClusterPSOCK() now attempt kill stray R processes. Note parallel::makePSOCKcluster() still problem.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-11-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.11.0","text":"makeClusterPSOCK() produces informative error messages whenever setup R workers fails. Also, verbose messages now prefixed “[local output]” help distinguish output produced current R session produced background workers. now possible specify type SSH clients makeClusterPSOCK() automatically searches order, e.g. rshcmd = c(\"<rstudio-ssh>\", \"<putty-plink>\"). Now makeClusterPSOCK() preserves global RNG state (.Random.seed) also draws random port number. makeClusterPSOCK() gained argument rshlogfile.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-11-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.11.0","text":"makeClusterPSOCK(..., rscript = \"my_r\") cases fail find intended my_r executable.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-10-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.10.0","text":"Add makeClusterMPI(n) creating MPI-based clusters similar kind parallel::makeCluster(n, type = \"MPI\") also attempts workaround issues parallel::stopCluster() causes R stall. makeClusterPSOCK() makeClusterMPI() gained argument autoStop controlling whether cluster automatically stopped garbage collected .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-9-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.9.0","text":"makeClusterPSOCK() produced warning environment variable R_PARALLEL_PORT set random (e.g. CRAN).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-8-1","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.8.1","text":"makeClusterPSOCK() now produces informative warning environment variable R_PARALLEL_PORT specifies non-numeric port.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-7-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.7.0","text":"Windows, makeClusterPSOCK(), therefore plan(multisession) plan(multiprocess), use SSH client distributed RStudio fallback neither ssh plink available system PATH.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-7-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.7.0","text":"makeClusterPSOCK(..., renice = 19) launch PSOCK worker via nice +19 resulting error “nice: ‘+19’: file directory”. bug inherited parallel::makePSOCKcluster(). Now using nice --adjustment=19 instead.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-5-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.5.0","text":"makeClusterPSOCK() now defaults use Windows PuTTY software’s SSH client plink -ssh, ssh found. Argument homogeneous makeNodePSOCK(), helper function makeClusterPSOCK(), default FALSE also hostname fully qualified domain name (FQDN), , “contains periods”. instance, c('node1', 'node2.server.org') use homogeneous = TRUE first worker homogeneous = FALSE second. makeClusterPSOCK() now asserts cluster node functioning retrieving recording node’s session information including process ID corresponding R process.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"documentation-1-5-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"Version 1.5.0","text":"Help makeClusterPSOCK() gained detailed descriptions arguments defaults .","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-4-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.4.0","text":"default values arguments connectTimeout timeout makeNodePSOCK() can now controlled via global options.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"deprecated-and-defunct-1-4-0","dir":"Changelog","previous_headings":"","what":"Deprecated and Defunct","title":"Version 1.4.0","text":"availableCores(method = \"mc.cores\") now defunct favor \"mc.cores+1\".","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-3-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.3.0","text":"makeClusterPSOCK() treats workers refer local machine local canonical hostname \"localhost\". avoids launch workers SSH, may supported systems / compute cluster. Added availableWorkers(). default returns localhost workers according availableCores(). addition, detects common HPC allocations given environment variables set HPC scheduler. Option future.availableCores.fallback, defaults environment variable R_FUTURE_AVAILABLECORES_FALLBACK can now used specify default number cores / workers returned availableCores() availableWorkers() settings available. instance, R_FUTURE_AVAILABLECORES_FALLBACK=1 set system wide HPC environment, R processes uses availableCores() detect many cores can used run single-core processes. Without fallback setting, without core-specifying settings, default use cores machine, play well multi-user systems.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-3-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.3.0","text":"Creation cluster futures (including multisession ones) time already 40 seconds workers busy. New default timeout 30 days (option future.wait.timeout). availableCores(methods = \"_R_CHECK_LIMIT_CORES_\") give error running R CMD check.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.2.0","text":"Added makeClusterPSOCK() - version parallel::makePSOCKcluster() allows flexible control PSOCK cluster workers set launched communicated running external machines. Added generic .cluster() coercing objects cluster objects used plan(cluster, workers = .cluster(x)). Also added c() implementation cluster objects multiple cluster objects can combined single one.","code":""},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.2.0","text":"Argument user remote() ignored (since 1.1.0).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-1-1-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 1.1.1","text":"special case ‘remote’ futures use workers =    \"localhost\" () use exact R executable main / calling R session (cases uses whatever Rscript found PATH). already indeed implemented 1.0.1, added support reverse SSH tunnels 1.1.0 default behavior lost.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-1-1-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 1.1.0","text":"REMOTE CLUSTERS: now simple use cluster() remote() connect remote clusters / machines. long can connect via SSH machines, works also future. new code completely avoids incoming firewall incoming port forwarding issues previously needed. done using reverse SSH tunneling. also need worry internal external IP numbers.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-15-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 0.15.0","text":"Now availableCores() also acknowledges environment variable NSLOTS set Sun/Oracle Grid Engine (SGE).","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"bug-fixes-0-12-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"Version 0.12.0","text":"FIX: Now availableCores() returns 3L (=2L+1L) instead 2L _R_CHECK_LIMIT_CORES_ set.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-10-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 0.10.0","text":"Now availableCores() also acknowledges number CPUs allotted Slurm.","code":""},{"path":[]},{"path":"https://parallelly.futureverse.org/news/index.html","id":"new-features-0-8-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"Version 0.8.0","text":"availableCores(\"mc.cores\") returns getOption(\"mc.cores\") + 1L, option mc.cores specifies “allowed number additional R processes” used addition main R process.","code":""}]
